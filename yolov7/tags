!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.8	//
A	utils/datasets.py	/^        import albumentations as A$/;"	i
AEROPLANE	deploy/triton-inference-server/labels.py	/^    AEROPLANE = 4$/;"	v	class:COCOLabels
APLoss	utils/loss.py	/^class APLoss(torch.autograd.Function):$/;"	c
APPLE	deploy/triton-inference-server/labels.py	/^    APPLE = 47$/;"	v	class:COCOLabels
Albumentations	utils/datasets.py	/^class Albumentations:$/;"	c
BACKPACK	deploy/triton-inference-server/labels.py	/^    BACKPACK = 24$/;"	v	class:COCOLabels
BANANA	deploy/triton-inference-server/labels.py	/^    BANANA = 46$/;"	v	class:COCOLabels
BASEBALL_BAT	deploy/triton-inference-server/labels.py	/^    BASEBALL_BAT = 34$/;"	v	class:COCOLabels
BASEBALL_GLOVE	deploy/triton-inference-server/labels.py	/^    BASEBALL_GLOVE = 35$/;"	v	class:COCOLabels
BCEBlurWithLogitsLoss	utils/loss.py	/^class BCEBlurWithLogitsLoss(nn.Module):$/;"	c
BEAR	deploy/triton-inference-server/labels.py	/^    BEAR = 21$/;"	v	class:COCOLabels
BED	deploy/triton-inference-server/labels.py	/^    BED = 59$/;"	v	class:COCOLabels
BENCH	deploy/triton-inference-server/labels.py	/^    BENCH = 13$/;"	v	class:COCOLabels
BICYCLE	deploy/triton-inference-server/labels.py	/^    BICYCLE = 1$/;"	v	class:COCOLabels
BIRD	deploy/triton-inference-server/labels.py	/^    BIRD = 14$/;"	v	class:COCOLabels
BOAT	deploy/triton-inference-server/labels.py	/^    BOAT = 8$/;"	v	class:COCOLabels
BOOK	deploy/triton-inference-server/labels.py	/^    BOOK = 73$/;"	v	class:COCOLabels
BOTTLE	deploy/triton-inference-server/labels.py	/^    BOTTLE = 39$/;"	v	class:COCOLabels
BOWL	deploy/triton-inference-server/labels.py	/^    BOWL = 45$/;"	v	class:COCOLabels
BROCCOLI	deploy/triton-inference-server/labels.py	/^    BROCCOLI = 50$/;"	v	class:COCOLabels
BUS	deploy/triton-inference-server/labels.py	/^    BUS = 5$/;"	v	class:COCOLabels
BatchNormXd	utils/torch_utils.py	/^class BatchNormXd(torch.nn.modules.batchnorm._BatchNorm):$/;"	c
Bottleneck	models/common.py	/^class Bottleneck(nn.Module):$/;"	c
BottleneckCSPA	models/common.py	/^class BottleneckCSPA(nn.Module):$/;"	c
BottleneckCSPB	models/common.py	/^class BottleneckCSPB(nn.Module):$/;"	c
BottleneckCSPC	models/common.py	/^class BottleneckCSPC(nn.Module):$/;"	c
BoundingBox	deploy/triton-inference-server/boundingbox.py	/^class BoundingBox:$/;"	c
BoundingBox	deploy/triton-inference-server/processing.py	/^from boundingbox import BoundingBox$/;"	i
CAKE	deploy/triton-inference-server/labels.py	/^    CAKE = 55$/;"	v	class:COCOLabels
CAR	deploy/triton-inference-server/labels.py	/^    CAR = 2$/;"	v	class:COCOLabels
CARROT	deploy/triton-inference-server/labels.py	/^    CARROT = 51$/;"	v	class:COCOLabels
CAT	deploy/triton-inference-server/labels.py	/^    CAT = 15$/;"	v	class:COCOLabels
CELL_PHONE	deploy/triton-inference-server/labels.py	/^    CELL_PHONE = 67$/;"	v	class:COCOLabels
CHAIR	deploy/triton-inference-server/labels.py	/^    CHAIR = 56$/;"	v	class:COCOLabels
CLOCK	deploy/triton-inference-server/labels.py	/^    CLOCK = 74$/;"	v	class:COCOLabels
COCO	test.py	/^            from pycocotools.coco import COCO$/;"	i
COCOLabels	deploy/triton-inference-server/client.py	/^from labels import COCOLabels$/;"	i
COCOLabels	deploy/triton-inference-server/labels.py	/^class COCOLabels(Enum):$/;"	c
COCOeval	test.py	/^            from pycocotools.cocoeval import COCOeval$/;"	i
COW	deploy/triton-inference-server/labels.py	/^    COW = 19$/;"	v	class:COCOLabels
CUP	deploy/triton-inference-server/labels.py	/^    CUP = 41$/;"	v	class:COCOLabels
Chuncat	models/common.py	/^class Chuncat(nn.Module):$/;"	c
Classify	models/common.py	/^class Classify(nn.Module):$/;"	c
ComputeLoss	train.py	/^from utils.loss import ComputeLoss, ComputeLossOTA$/;"	i
ComputeLoss	train_aux.py	/^from utils.loss import ComputeLoss, ComputeLossAuxOTA$/;"	i
ComputeLoss	utils/loss.py	/^class ComputeLoss:$/;"	c
ComputeLossAuxOTA	train_aux.py	/^from utils.loss import ComputeLoss, ComputeLossAuxOTA$/;"	i
ComputeLossAuxOTA	utils/loss.py	/^class ComputeLossAuxOTA:$/;"	c
ComputeLossBinOTA	utils/loss.py	/^class ComputeLossBinOTA:$/;"	c
ComputeLossOTA	train.py	/^from utils.loss import ComputeLoss, ComputeLossOTA$/;"	i
ComputeLossOTA	utils/loss.py	/^class ComputeLossOTA:$/;"	c
Concat	models/common.py	/^class Concat(nn.Module):$/;"	c
ConfusionMatrix	test.py	/^from utils.metrics import ap_per_class, ConfusionMatrix$/;"	i
ConfusionMatrix	utils/metrics.py	/^class ConfusionMatrix:$/;"	c
Contract	models/common.py	/^class Contract(nn.Module):$/;"	c
Conv	models/common.py	/^class Conv(nn.Module):$/;"	c
Conv	models/experimental.py	/^from models.common import Conv, DWConv$/;"	i
ConvBN	models/common.py	/^class ConvBN(nn.Module):$/;"	c
CrossConv	models/experimental.py	/^class CrossConv(nn.Module):$/;"	c
DDP	train.py	/^from torch.nn.parallel import DistributedDataParallel as DDP$/;"	i
DDP	train_aux.py	/^from torch.nn.parallel import DistributedDataParallel as DDP$/;"	i
DININGTABLE	deploy/triton-inference-server/labels.py	/^    DININGTABLE = 60$/;"	v	class:COCOLabels
DOG	deploy/triton-inference-server/labels.py	/^    DOG = 16$/;"	v	class:COCOLabels
DONUT	deploy/triton-inference-server/labels.py	/^    DONUT = 54$/;"	v	class:COCOLabels
DWConv	models/common.py	/^def DWConv(c1, c2, k=1, s=1, act=True):$/;"	f
DWConv	models/experimental.py	/^from models.common import Conv, DWConv$/;"	i
Dataset	utils/datasets.py	/^from torch.utils.data import Dataset$/;"	i
DeformConv2d	models/common.py	/^from torchvision.ops import DeformConv2d$/;"	i
Detect	models/yolo.py	/^class Detect(nn.Module):$/;"	c
Detections	models/common.py	/^class Detections:$/;"	c
DownC	models/common.py	/^class DownC(nn.Module):$/;"	c
ELEPHANT	deploy/triton-inference-server/labels.py	/^    ELEPHANT = 20$/;"	v	class:COCOLabels
End2End	export.py	/^from models.experimental import attempt_load, End2End$/;"	i
End2End	models/experimental.py	/^class End2End(nn.Module):$/;"	c
Ensemble	models/experimental.py	/^class Ensemble(nn.ModuleList):$/;"	c
Enum	deploy/triton-inference-server/labels.py	/^from enum import Enum$/;"	i
ExifTags	utils/datasets.py	/^from PIL import Image, ExifTags$/;"	i
Expand	models/common.py	/^class Expand(nn.Module):$/;"	c
F	models/common.py	/^import torch.nn.functional as F$/;"	i
F	train.py	/^import torch.nn.functional as F$/;"	i
F	train_aux.py	/^import torch.nn.functional as F$/;"	i
F	utils/activations.py	/^    class F(torch.autograd.Function):$/;"	c	class:MemoryEfficientMish
F	utils/activations.py	/^    class F(torch.autograd.Function):$/;"	c	class:MemoryEfficientSwish
F	utils/activations.py	/^import torch.nn.functional as F$/;"	i
F	utils/datasets.py	/^import torch.nn.functional as F$/;"	i
F	utils/loss.py	/^import torch.nn.functional as F$/;"	i
F	utils/torch_utils.py	/^import torch.nn.functional as F$/;"	i
FIRE_HYDRANT	deploy/triton-inference-server/labels.py	/^    FIRE_HYDRANT = 10$/;"	v	class:COCOLabels
FLAGS	deploy/triton-inference-server/client.py	/^    FLAGS = parser.parse_args()$/;"	v
FLOPS	models/yolo.py	/^    import thop  # for FLOPS computation$/;"	i
FLOPS	utils/torch_utils.py	/^    import thop  # for FLOPS computation$/;"	i
FORK	deploy/triton-inference-server/labels.py	/^    FORK = 42$/;"	v	class:COCOLabels
FRISBEE	deploy/triton-inference-server/labels.py	/^    FRISBEE = 29$/;"	v	class:COCOLabels
FReLU	utils/activations.py	/^class FReLU(nn.Module):$/;"	c
FocalLoss	utils/loss.py	/^class FocalLoss(nn.Module):$/;"	c
Focus	models/common.py	/^class Focus(nn.Module):$/;"	c
Foldcut	models/common.py	/^class Foldcut(nn.Module):$/;"	c
GIRAFFE	deploy/triton-inference-server/labels.py	/^    GIRAFFE = 23$/;"	v	class:COCOLabels
Ghost	models/common.py	/^class Ghost(nn.Module):$/;"	c
GhostCSPA	models/common.py	/^class GhostCSPA(BottleneckCSPA):$/;"	c
GhostCSPB	models/common.py	/^class GhostCSPB(BottleneckCSPB):$/;"	c
GhostCSPC	models/common.py	/^class GhostCSPC(BottleneckCSPC):$/;"	c
GhostConv	models/common.py	/^class GhostConv(nn.Module):$/;"	c
GhostSPPCSPC	models/common.py	/^class GhostSPPCSPC(SPPCSPC):$/;"	c
GhostStem	models/common.py	/^class GhostStem(Stem):$/;"	c
HAIR_DRIER	deploy/triton-inference-server/labels.py	/^    HAIR_DRIER = 78$/;"	v	class:COCOLabels
HANDBAG	deploy/triton-inference-server/labels.py	/^    HANDBAG = 26$/;"	v	class:COCOLabels
HORSE	deploy/triton-inference-server/labels.py	/^    HORSE = 17$/;"	v	class:COCOLabels
HOT_DOG	deploy/triton-inference-server/labels.py	/^    HOT_DOG = 52$/;"	v	class:COCOLabels
Hardswish	export.py	/^from utils.activations import Hardswish, SiLU$/;"	i
Hardswish	utils/activations.py	/^class Hardswish(nn.Module):  # export-friendly version of nn.Hardswish()$/;"	c
IAuxDetect	models/yolo.py	/^class IAuxDetect(nn.Module):$/;"	c
IBin	models/yolo.py	/^class IBin(nn.Module):$/;"	c
IDetect	models/yolo.py	/^class IDetect(nn.Module):$/;"	c
IKeypoint	models/yolo.py	/^class IKeypoint(nn.Module):$/;"	c
INPUT_NAMES	deploy/triton-inference-server/client.py	/^INPUT_NAMES = ["images"]$/;"	v
Image	hubconf.py	/^    from PIL import Image$/;"	i
Image	models/common.py	/^from PIL import Image$/;"	i
Image	utils/datasets.py	/^from PIL import Image, ExifTags$/;"	i
Image	utils/plots.py	/^from PIL import Image, ImageDraw, ImageFont$/;"	i
ImageDraw	utils/plots.py	/^from PIL import Image, ImageDraw, ImageFont$/;"	i
ImageFont	utils/plots.py	/^from PIL import Image, ImageDraw, ImageFont$/;"	i
ImplicitA	models/common.py	/^class ImplicitA(nn.Module):$/;"	c
ImplicitM	models/common.py	/^class ImplicitM(nn.Module):$/;"	c
InferenceServerException	deploy/triton-inference-server/client.py	/^from tritonclient.utils import InferenceServerException$/;"	i
InfiniteDataLoader	utils/datasets.py	/^class InfiniteDataLoader(torch.utils.data.dataloader.DataLoader):$/;"	c
KEYBOARD	deploy/triton-inference-server/labels.py	/^    KEYBOARD = 66$/;"	v	class:COCOLabels
KITE	deploy/triton-inference-server/labels.py	/^    KITE = 33$/;"	v	class:COCOLabels
KNIFE	deploy/triton-inference-server/labels.py	/^    KNIFE = 43$/;"	v	class:COCOLabels
LAPTOP	deploy/triton-inference-server/labels.py	/^    LAPTOP = 63$/;"	v	class:COCOLabels
LOGGER	utils/add_nms.py	/^LOGGER = logging.getLogger(__name__)$/;"	v
LoadImages	detect.py	/^from utils.datasets import LoadStreams, LoadImages$/;"	i
LoadImages	utils/datasets.py	/^class LoadImages:  # for inference$/;"	c
LoadImagesAndLabels	utils/autoanchor.py	/^        from utils.datasets import LoadImagesAndLabels$/;"	i
LoadImagesAndLabels	utils/datasets.py	/^class LoadImagesAndLabels(Dataset):  # for training\/testing$/;"	c
LoadImagesAndLabels	utils/wandb_logging/wandb_utils.py	/^from utils.datasets import LoadImagesAndLabels$/;"	i
LoadStreams	detect.py	/^from utils.datasets import LoadStreams, LoadImages$/;"	i
LoadStreams	utils/datasets.py	/^class LoadStreams:  # multiple IP or RTSP cameras$/;"	c
LoadWebcam	utils/datasets.py	/^class LoadWebcam:  # for inference$/;"	c
MICROWAVE	deploy/triton-inference-server/labels.py	/^    MICROWAVE = 68$/;"	v	class:COCOLabels
MOTORBIKE	deploy/triton-inference-server/labels.py	/^    MOTORBIKE = 3$/;"	v	class:COCOLabels
MOUSE	deploy/triton-inference-server/labels.py	/^    MOUSE = 64$/;"	v	class:COCOLabels
MP	models/common.py	/^class MP(nn.Module):$/;"	c
MemoryEfficientMish	utils/activations.py	/^class MemoryEfficientMish(nn.Module):$/;"	c
MemoryEfficientSwish	utils/activations.py	/^class MemoryEfficientSwish(nn.Module):$/;"	c
Mish	utils/activations.py	/^class Mish(nn.Module):$/;"	c
MixConv2d	models/experimental.py	/^class MixConv2d(nn.Module):$/;"	c
Mlp	models/common.py	/^class Mlp(nn.Module):$/;"	c
Mlp_v2	models/common.py	/^class Mlp_v2(nn.Module):$/;"	c
Model	hubconf.py	/^from models.yolo import Model$/;"	i
Model	models/yolo.py	/^class Model(nn.Module):$/;"	c
Model	train.py	/^from models.yolo import Model$/;"	i
Model	train_aux.py	/^from models.yolo import Model$/;"	i
ModelEMA	train.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
ModelEMA	train_aux.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
ModelEMA	utils/torch_utils.py	/^class ModelEMA:$/;"	c
NMS	models/common.py	/^class NMS(nn.Module):$/;"	c
ONNX_ORT	models/experimental.py	/^class ONNX_ORT(nn.Module):$/;"	c
ONNX_TRT	models/experimental.py	/^class ONNX_TRT(nn.Module):$/;"	c
ORANGE	deploy/triton-inference-server/labels.py	/^    ORANGE = 49$/;"	v	class:COCOLabels
OREPA_3x3_RepConv	models/common.py	/^class OREPA_3x3_RepConv(nn.Module):$/;"	c
ORT_NMS	models/experimental.py	/^class ORT_NMS(torch.autograd.Function):$/;"	c
OUTPUT_NAMES	deploy/triton-inference-server/client.py	/^OUTPUT_NAMES = ["num_dets", "det_boxes", "det_scores", "det_classes"]$/;"	v
OVEN	deploy/triton-inference-server/labels.py	/^    OVEN = 69$/;"	v	class:COCOLabels
PARKING_METER	deploy/triton-inference-server/labels.py	/^    PARKING_METER = 12$/;"	v	class:COCOLabels
PERSON	deploy/triton-inference-server/labels.py	/^    PERSON = 0$/;"	v	class:COCOLabels
PIZZA	deploy/triton-inference-server/labels.py	/^    PIZZA = 53$/;"	v	class:COCOLabels
POTTEDPLANT	deploy/triton-inference-server/labels.py	/^    POTTEDPLANT = 58$/;"	v	class:COCOLabels
Path	detect.py	/^from pathlib import Path$/;"	i
Path	hubconf.py	/^from pathlib import Path$/;"	i
Path	models/common.py	/^from pathlib import Path$/;"	i
Path	test.py	/^from pathlib import Path$/;"	i
Path	train.py	/^from pathlib import Path$/;"	i
Path	train_aux.py	/^from pathlib import Path$/;"	i
Path	utils/aws/resume.py	/^from pathlib import Path$/;"	i
Path	utils/datasets.py	/^from pathlib import Path$/;"	i
Path	utils/general.py	/^from pathlib import Path$/;"	i
Path	utils/google_utils.py	/^from pathlib import Path$/;"	i
Path	utils/metrics.py	/^from pathlib import Path$/;"	i
Path	utils/plots.py	/^from pathlib import Path$/;"	i
Path	utils/torch_utils.py	/^from pathlib import Path$/;"	i
Path	utils/wandb_logging/wandb_utils.py	/^from pathlib import Path$/;"	i
QFocalLoss	utils/loss.py	/^class QFocalLoss(nn.Module):$/;"	c
RAND_COLORS	deploy/triton-inference-server/client.py	/^from render import render_box, render_filled_box, get_text_size, render_text, RAND_COLORS$/;"	i
RAND_COLORS	deploy/triton-inference-server/render.py	/^RAND_COLORS = np.random.randint(50, 255, (64, 3), "int")  # used for class visu$/;"	v
REFRIGERATOR	deploy/triton-inference-server/labels.py	/^    REFRIGERATOR = 72$/;"	v	class:COCOLabels
REMOTE	deploy/triton-inference-server/labels.py	/^    REMOTE = 65$/;"	v	class:COCOLabels
RankSort	utils/loss.py	/^class RankSort(torch.autograd.Function):$/;"	c
ReOrg	models/common.py	/^class ReOrg(nn.Module):$/;"	c
RegisterNMS	export.py	/^from utils.add_nms import RegisterNMS$/;"	i
RegisterNMS	utils/add_nms.py	/^class RegisterNMS(object):$/;"	c
RepBottleneck	models/common.py	/^class RepBottleneck(Bottleneck):$/;"	c
RepBottleneckCSPA	models/common.py	/^class RepBottleneckCSPA(BottleneckCSPA):$/;"	c
RepBottleneckCSPB	models/common.py	/^class RepBottleneckCSPB(BottleneckCSPB):$/;"	c
RepBottleneckCSPC	models/common.py	/^class RepBottleneckCSPC(BottleneckCSPC):$/;"	c
RepConv	models/common.py	/^class RepConv(nn.Module):$/;"	c
RepConv_OREPA	models/common.py	/^class RepConv_OREPA(nn.Module):$/;"	c
RepRes	models/common.py	/^class RepRes(Res):$/;"	c
RepResCSPA	models/common.py	/^class RepResCSPA(ResCSPA):$/;"	c
RepResCSPB	models/common.py	/^class RepResCSPB(ResCSPB):$/;"	c
RepResCSPC	models/common.py	/^class RepResCSPC(ResCSPC):$/;"	c
RepResX	models/common.py	/^class RepResX(ResX):$/;"	c
RepResXCSPA	models/common.py	/^class RepResXCSPA(ResXCSPA):$/;"	c
RepResXCSPB	models/common.py	/^class RepResXCSPB(ResXCSPB):$/;"	c
RepResXCSPC	models/common.py	/^class RepResXCSPC(ResXCSPC):$/;"	c
Res	models/common.py	/^class Res(nn.Module):$/;"	c
ResCSPA	models/common.py	/^class ResCSPA(BottleneckCSPA):$/;"	c
ResCSPB	models/common.py	/^class ResCSPB(BottleneckCSPB):$/;"	c
ResCSPC	models/common.py	/^class ResCSPC(BottleneckCSPC):$/;"	c
ResX	models/common.py	/^class ResX(Res):$/;"	c
ResXCSPA	models/common.py	/^class ResXCSPA(ResCSPA):$/;"	c
ResXCSPB	models/common.py	/^class ResXCSPB(ResCSPB):$/;"	c
ResXCSPC	models/common.py	/^class ResXCSPC(ResCSPC):$/;"	c
RobustConv	models/common.py	/^class RobustConv(nn.Module):$/;"	c
RobustConv2	models/common.py	/^class RobustConv2(nn.Module):$/;"	c
SANDWICH	deploy/triton-inference-server/labels.py	/^    SANDWICH = 48$/;"	v	class:COCOLabels
SCISSORS	deploy/triton-inference-server/labels.py	/^    SCISSORS = 76$/;"	v	class:COCOLabels
SHEEP	deploy/triton-inference-server/labels.py	/^    SHEEP = 18$/;"	v	class:COCOLabels
SINK	deploy/triton-inference-server/labels.py	/^    SINK = 71$/;"	v	class:COCOLabels
SKATEBOARD	deploy/triton-inference-server/labels.py	/^    SKATEBOARD = 36$/;"	v	class:COCOLabels
SKIS	deploy/triton-inference-server/labels.py	/^    SKIS = 30$/;"	v	class:COCOLabels
SNOWBOARD	deploy/triton-inference-server/labels.py	/^    SNOWBOARD = 31$/;"	v	class:COCOLabels
SOFA	deploy/triton-inference-server/labels.py	/^    SOFA = 57$/;"	v	class:COCOLabels
SP	models/common.py	/^class SP(nn.Module):$/;"	c
SPOON	deploy/triton-inference-server/labels.py	/^    SPOON = 44$/;"	v	class:COCOLabels
SPORTS_BALL	deploy/triton-inference-server/labels.py	/^    SPORTS_BALL = 32$/;"	v	class:COCOLabels
SPP	models/common.py	/^class SPP(nn.Module):$/;"	c
SPPCSPC	models/common.py	/^class SPPCSPC(nn.Module):$/;"	c
SPPF	models/common.py	/^class SPPF(nn.Module):$/;"	c
ST2CSPA	models/common.py	/^class ST2CSPA(nn.Module):$/;"	c
ST2CSPB	models/common.py	/^class ST2CSPB(nn.Module):$/;"	c
ST2CSPC	models/common.py	/^class ST2CSPC(nn.Module):$/;"	c
STCSPA	models/common.py	/^class STCSPA(nn.Module):$/;"	c
STCSPB	models/common.py	/^class STCSPB(nn.Module):$/;"	c
STCSPC	models/common.py	/^class STCSPC(nn.Module):$/;"	c
STOP_SIGN	deploy/triton-inference-server/labels.py	/^    STOP_SIGN = 11$/;"	v	class:COCOLabels
SUITCASE	deploy/triton-inference-server/labels.py	/^    SUITCASE = 28$/;"	v	class:COCOLabels
SURFBOARD	deploy/triton-inference-server/labels.py	/^    SURFBOARD = 37$/;"	v	class:COCOLabels
Shortcut	models/common.py	/^class Shortcut(nn.Module):$/;"	c
SiLU	export.py	/^from utils.activations import Hardswish, SiLU$/;"	i
SiLU	utils/activations.py	/^class SiLU(nn.Module):  # export-friendly version of nn.SiLU()$/;"	c
SigmoidBin	models/yolo.py	/^from utils.loss import SigmoidBin$/;"	i
SigmoidBin	utils/loss.py	/^class SigmoidBin(nn.Module):$/;"	c
Stem	models/common.py	/^class Stem(nn.Module):$/;"	c
Sum	models/experimental.py	/^class Sum(nn.Module):$/;"	c
SummaryWriter	train.py	/^from torch.utils.tensorboard import SummaryWriter$/;"	i
SummaryWriter	train_aux.py	/^from torch.utils.tensorboard import SummaryWriter$/;"	i
SwinTransformer2Block	models/common.py	/^class SwinTransformer2Block(nn.Module):$/;"	c
SwinTransformerBlock	models/common.py	/^class SwinTransformerBlock(nn.Module):$/;"	c
SwinTransformerLayer	models/common.py	/^class SwinTransformerLayer(nn.Module):$/;"	c
SwinTransformerLayer_v2	models/common.py	/^class SwinTransformerLayer_v2(nn.Module):$/;"	c
TEDDY_BEAR	deploy/triton-inference-server/labels.py	/^    TEDDY_BEAR = 77$/;"	v	class:COCOLabels
TENNIS_RACKET	deploy/triton-inference-server/labels.py	/^    TENNIS_RACKET = 38$/;"	v	class:COCOLabels
TIE	deploy/triton-inference-server/labels.py	/^    TIE = 27$/;"	v	class:COCOLabels
TOASTER	deploy/triton-inference-server/labels.py	/^    TOASTER = 70$/;"	v	class:COCOLabels
TOILET	deploy/triton-inference-server/labels.py	/^    TOILET = 61$/;"	v	class:COCOLabels
TOOTHBRUSH	deploy/triton-inference-server/labels.py	/^    TOOTHBRUSH = 79$/;"	v	class:COCOLabels
TRAFFIC_LIGHT	deploy/triton-inference-server/labels.py	/^    TRAFFIC_LIGHT = 9$/;"	v	class:COCOLabels
TRAIN	deploy/triton-inference-server/labels.py	/^    TRAIN = 6$/;"	v	class:COCOLabels
TRT_NMS	models/experimental.py	/^class TRT_NMS(torch.autograd.Function):$/;"	c
TRUCK	deploy/triton-inference-server/labels.py	/^    TRUCK = 7$/;"	v	class:COCOLabels
TVMONITOR	deploy/triton-inference-server/labels.py	/^    TVMONITOR = 62$/;"	v	class:COCOLabels
Thread	test.py	/^from threading import Thread$/;"	i
Thread	train.py	/^from threading import Thread$/;"	i
Thread	train_aux.py	/^from threading import Thread$/;"	i
Thread	utils/datasets.py	/^from threading import Thread$/;"	i
ThreadPool	utils/datasets.py	/^from multiprocessing.pool import ThreadPool$/;"	i
TracedModel	detect.py	/^from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel$/;"	i
TracedModel	test.py	/^from utils.torch_utils import select_device, time_synchronized, TracedModel$/;"	i
TracedModel	utils/torch_utils.py	/^class TracedModel(nn.Module):$/;"	c
TransformerBlock	models/common.py	/^class TransformerBlock(nn.Module):$/;"	c
TransformerLayer	models/common.py	/^class TransformerLayer(nn.Module):$/;"	c
UMBRELLA	deploy/triton-inference-server/labels.py	/^    UMBRELLA = 25$/;"	v	class:COCOLabels
VASE	deploy/triton-inference-server/labels.py	/^    VASE = 75$/;"	v	class:COCOLabels
WANDB_ARTIFACT_PREFIX	utils/wandb_logging/log_dataset.py	/^WANDB_ARTIFACT_PREFIX = 'wandb-artifact:\/\/'$/;"	v
WANDB_ARTIFACT_PREFIX	utils/wandb_logging/wandb_utils.py	/^WANDB_ARTIFACT_PREFIX = 'wandb-artifact:\/\/'$/;"	v
WINE_GLASS	deploy/triton-inference-server/labels.py	/^    WINE_GLASS = 40$/;"	v	class:COCOLabels
WandbLogger	train.py	/^from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume$/;"	i
WandbLogger	train_aux.py	/^from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume$/;"	i
WandbLogger	utils/wandb_logging/log_dataset.py	/^from wandb_utils import WandbLogger$/;"	i
WandbLogger	utils/wandb_logging/wandb_utils.py	/^class WandbLogger():$/;"	c
WindowAttention	models/common.py	/^class WindowAttention(nn.Module):$/;"	c
WindowAttention_v2	models/common.py	/^class WindowAttention_v2(nn.Module):$/;"	c
ZEBRA	deploy/triton-inference-server/labels.py	/^    ZEBRA = 22$/;"	v	class:COCOLabels
_LINE_THICKNESS_SCALING	deploy/triton-inference-server/render.py	/^_LINE_THICKNESS_SCALING = 500.0$/;"	v
_RepeatSampler	utils/datasets.py	/^class _RepeatSampler(object):$/;"	c
_TEXT_SCALING	deploy/triton-inference-server/render.py	/^_TEXT_SCALING = 520.0$/;"	v
_TEXT_THICKNESS_SCALING	deploy/triton-inference-server/render.py	/^_TEXT_THICKNESS_SCALING = 700.0$/;"	v
__call__	utils/datasets.py	/^    def __call__(self, im, labels, p=1.0):$/;"	m	class:Albumentations	file:
__call__	utils/loss.py	/^    def __call__(self, p, targets):  # predictions, targets, model$/;"	m	class:ComputeLoss	file:
__call__	utils/loss.py	/^    def __call__(self, p, targets, imgs):  # predictions, targets, model   $/;"	m	class:ComputeLossAuxOTA	file:
__call__	utils/loss.py	/^    def __call__(self, p, targets, imgs):  # predictions, targets, model   $/;"	m	class:ComputeLossBinOTA	file:
__call__	utils/loss.py	/^    def __call__(self, p, targets, imgs):  # predictions, targets, model   $/;"	m	class:ComputeLossOTA	file:
__getitem__	utils/datasets.py	/^    def __getitem__(self, index):$/;"	m	class:LoadImagesAndLabels	file:
__init__	deploy/triton-inference-server/boundingbox.py	/^    def __init__(self, classID, confidence, x1, x2, y1, y2, image_width, image_height):$/;"	m	class:BoundingBox
__init__	models/common.py	/^    def __init__(self):$/;"	m	class:NMS
__init__	models/common.py	/^    def __init__(self):$/;"	m	class:ReOrg
__init__	models/common.py	/^    def __init__(self, c, num_heads):$/;"	m	class:TransformerLayer
__init__	models/common.py	/^    def __init__(self, c1, c2, k=(5, 9, 13)):$/;"	m	class:SPP
__init__	models/common.py	/^    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups$/;"	m	class:GhostConv
__init__	models/common.py	/^    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:Classify
__init__	models/common.py	/^    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:Conv
__init__	models/common.py	/^    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:Focus
__init__	models/common.py	/^    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:GhostStem
__init__	models/common.py	/^    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:Stem
__init__	models/common.py	/^    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride$/;"	m	class:Ghost
__init__	models/common.py	/^    def __init__(self, c1, c2, k=3, s=1, p=None, g=1, act=True, deploy=False):$/;"	m	class:RepConv
__init__	models/common.py	/^    def __init__(self, c1, c2, k=3, s=1, padding=1, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False, nonlinear=nn.SiLU()):$/;"	m	class:RepConv_OREPA
__init__	models/common.py	/^    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))$/;"	m	class:SPPF
__init__	models/common.py	/^    def __init__(self, c1, c2, k=7, s=1, p=None, g=1, act=True, layer_scale_init_value=1e-6):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:RobustConv
__init__	models/common.py	/^    def __init__(self, c1, c2, k=7, s=4, p=None, g=1, act=True, layer_scale_init_value=1e-6):  # ch_in, ch_out, kernel, stride, padding, groups$/;"	m	class:RobustConv2
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, k=2):$/;"	m	class:DownC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:BottleneckCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepBottleneckCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepResCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ST2CSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:STCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, k=(5, 9, 13)):$/;"	m	class:GhostSPPCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, k=(5, 9, 13)):$/;"	m	class:SPPCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=False, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepResXCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:BottleneckCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:BottleneckCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:GhostCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:GhostCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:GhostCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepBottleneckCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepBottleneckCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepResCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepResCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ResCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ResCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ResCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ST2CSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ST2CSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:STCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:STCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepResXCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:RepResXCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ResXCSPA
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ResXCSPB
__init__	models/common.py	/^    def __init__(self, c1, c2, n=1, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion$/;"	m	class:ResXCSPC
__init__	models/common.py	/^    def __init__(self, c1, c2, num_heads, num_layers):$/;"	m	class:TransformerBlock
__init__	models/common.py	/^    def __init__(self, c1, c2, num_heads, num_layers, window_size=7):$/;"	m	class:SwinTransformer2Block
__init__	models/common.py	/^    def __init__(self, c1, c2, num_heads, num_layers, window_size=8):$/;"	m	class:SwinTransformerBlock
__init__	models/common.py	/^    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion$/;"	m	class:Bottleneck
__init__	models/common.py	/^    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion$/;"	m	class:RepBottleneck
__init__	models/common.py	/^    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion$/;"	m	class:RepRes
__init__	models/common.py	/^    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion$/;"	m	class:Res
__init__	models/common.py	/^    def __init__(self, c1, c2, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion$/;"	m	class:RepResX
__init__	models/common.py	/^    def __init__(self, c1, c2, shortcut=True, g=32, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion$/;"	m	class:ResX
__init__	models/common.py	/^    def __init__(self, channel, mean=0., std=.02):$/;"	m	class:ImplicitA
__init__	models/common.py	/^    def __init__(self, channel, mean=1., std=.02):$/;"	m	class:ImplicitM
__init__	models/common.py	/^    def __init__(self, dim, num_heads, window_size=7, shift_size=0,$/;"	m	class:SwinTransformerLayer_v2
__init__	models/common.py	/^    def __init__(self, dim, num_heads, window_size=8, shift_size=0,$/;"	m	class:SwinTransformerLayer
__init__	models/common.py	/^    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.,$/;"	m	class:WindowAttention_v2
__init__	models/common.py	/^    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):$/;"	m	class:WindowAttention
__init__	models/common.py	/^    def __init__(self, dimension=0):$/;"	m	class:Foldcut
__init__	models/common.py	/^    def __init__(self, dimension=0):$/;"	m	class:Shortcut
__init__	models/common.py	/^    def __init__(self, dimension=1):$/;"	m	class:Chuncat
__init__	models/common.py	/^    def __init__(self, dimension=1):$/;"	m	class:Concat
__init__	models/common.py	/^    def __init__(self, gain=2):$/;"	m	class:Contract
__init__	models/common.py	/^    def __init__(self, gain=2):$/;"	m	class:Expand
__init__	models/common.py	/^    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):$/;"	m	class:Detections
__init__	models/common.py	/^    def __init__(self, in_channels, out_channels, kernel_size,$/;"	m	class:ConvBN
__init__	models/common.py	/^    def __init__(self, in_channels, out_channels, kernel_size,$/;"	m	class:OREPA_3x3_RepConv
__init__	models/common.py	/^    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.SiLU, drop=0.):$/;"	m	class:Mlp
__init__	models/common.py	/^    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.SiLU, drop=0.):$/;"	m	class:Mlp_v2
__init__	models/common.py	/^    def __init__(self, k=2):$/;"	m	class:MP
__init__	models/common.py	/^    def __init__(self, k=3, s=1):$/;"	m	class:SP
__init__	models/common.py	/^    def __init__(self, model):$/;"	m	class:autoShape
__init__	models/experimental.py	/^    def __init__(self):$/;"	m	class:Ensemble
__init__	models/experimental.py	/^    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):$/;"	m	class:MixConv2d
__init__	models/experimental.py	/^    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):$/;"	m	class:CrossConv
__init__	models/experimental.py	/^    def __init__(self, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=640, device=None, n_classes=80):$/;"	m	class:ONNX_ORT
__init__	models/experimental.py	/^    def __init__(self, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=None ,device=None, n_classes=80):$/;"	m	class:ONNX_TRT
__init__	models/experimental.py	/^    def __init__(self, model, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=None, device=None, n_classes=80):$/;"	m	class:End2End
__init__	models/experimental.py	/^    def __init__(self, n, weight=False):  # n: number of inputs$/;"	m	class:Sum
__init__	models/yolo.py	/^    def __init__(self, cfg='yolor-csp-c.yaml', ch=3, nc=None, anchors=None):  # model, input channels, number of classes$/;"	m	class:Model
__init__	models/yolo.py	/^    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer$/;"	m	class:Detect
__init__	models/yolo.py	/^    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer$/;"	m	class:IAuxDetect
__init__	models/yolo.py	/^    def __init__(self, nc=80, anchors=(), ch=()):  # detection layer$/;"	m	class:IDetect
__init__	models/yolo.py	/^    def __init__(self, nc=80, anchors=(), ch=(), bin_count=21):  # detection layer$/;"	m	class:IBin
__init__	models/yolo.py	/^    def __init__(self, nc=80, anchors=(), nkpt=17, ch=(), inplace=True, dw_conv_kpt=False):  # detection layer$/;"	m	class:IKeypoint
__init__	utils/activations.py	/^    def __init__(self, c1, k=3):  # ch_in, kernel$/;"	m	class:FReLU
__init__	utils/add_nms.py	/^    def __init__($/;"	m	class:RegisterNMS
__init__	utils/datasets.py	/^    def __init__(self):$/;"	m	class:Albumentations
__init__	utils/datasets.py	/^    def __init__(self, *args, **kwargs):$/;"	m	class:InfiniteDataLoader
__init__	utils/datasets.py	/^    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,$/;"	m	class:LoadImagesAndLabels
__init__	utils/datasets.py	/^    def __init__(self, path, img_size=640, stride=32):$/;"	m	class:LoadImages
__init__	utils/datasets.py	/^    def __init__(self, pipe='0', img_size=640, stride=32):$/;"	m	class:LoadWebcam
__init__	utils/datasets.py	/^    def __init__(self, sampler):$/;"	m	class:_RepeatSampler
__init__	utils/datasets.py	/^    def __init__(self, sources='streams.txt', img_size=640, stride=32):$/;"	m	class:LoadStreams
__init__	utils/loss.py	/^    def __init__(self, alpha=0.05):$/;"	m	class:BCEBlurWithLogitsLoss
__init__	utils/loss.py	/^    def __init__(self, bin_count=10, min=0.0, max=1.0, reg_scale = 2.0, use_loss_regression=True, use_fw_regression=True, BCE_weight=1.0, smooth_eps=0.0):$/;"	m	class:SigmoidBin
__init__	utils/loss.py	/^    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):$/;"	m	class:FocalLoss
__init__	utils/loss.py	/^    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):$/;"	m	class:QFocalLoss
__init__	utils/loss.py	/^    def __init__(self, model, autobalance=False):$/;"	m	class:ComputeLoss
__init__	utils/loss.py	/^    def __init__(self, model, autobalance=False):$/;"	m	class:ComputeLossAuxOTA
__init__	utils/loss.py	/^    def __init__(self, model, autobalance=False):$/;"	m	class:ComputeLossBinOTA
__init__	utils/loss.py	/^    def __init__(self, model, autobalance=False):$/;"	m	class:ComputeLossOTA
__init__	utils/metrics.py	/^    def __init__(self, nc, conf=0.25, iou_thres=0.45):$/;"	m	class:ConfusionMatrix
__init__	utils/torch_utils.py	/^    def __init__(self, model, decay=0.9999, updates=0):$/;"	m	class:ModelEMA
__init__	utils/torch_utils.py	/^    def __init__(self, model=None, device=None, img_size=(640,640)): $/;"	m	class:TracedModel
__init__	utils/wandb_logging/wandb_utils.py	/^    def __init__(self, opt, name, run_id, data_dict, job_type='Training'):$/;"	m	class:WandbLogger
__iter__	utils/datasets.py	/^    def __iter__(self):$/;"	m	class:InfiniteDataLoader	file:
__iter__	utils/datasets.py	/^    def __iter__(self):$/;"	m	class:LoadImages	file:
__iter__	utils/datasets.py	/^    def __iter__(self):$/;"	m	class:LoadStreams	file:
__iter__	utils/datasets.py	/^    def __iter__(self):$/;"	m	class:LoadWebcam	file:
__iter__	utils/datasets.py	/^    def __iter__(self):$/;"	m	class:_RepeatSampler	file:
__len__	models/common.py	/^    def __len__(self):$/;"	m	class:Detections	file:
__len__	utils/datasets.py	/^    def __len__(self):$/;"	m	class:InfiniteDataLoader	file:
__len__	utils/datasets.py	/^    def __len__(self):$/;"	m	class:LoadImages	file:
__len__	utils/datasets.py	/^    def __len__(self):$/;"	m	class:LoadImagesAndLabels	file:
__len__	utils/datasets.py	/^    def __len__(self):$/;"	m	class:LoadStreams	file:
__len__	utils/datasets.py	/^    def __len__(self):$/;"	m	class:LoadWebcam	file:
__next__	utils/datasets.py	/^    def __next__(self):$/;"	m	class:LoadImages	file:
__next__	utils/datasets.py	/^    def __next__(self):$/;"	m	class:LoadStreams	file:
__next__	utils/datasets.py	/^    def __next__(self):$/;"	m	class:LoadWebcam	file:
_check_input_dim	utils/torch_utils.py	/^    def _check_input_dim(self, input):$/;"	m	class:BatchNormXd
_fuse_bn_tensor	models/common.py	/^    def _fuse_bn_tensor(self, branch):$/;"	m	class:RepConv
_fuse_bn_tensor	models/common.py	/^    def _fuse_bn_tensor(self, branch):$/;"	m	class:RepConv_OREPA
_initialize_aux_biases	models/yolo.py	/^    def _initialize_aux_biases(self, cf=None):  # initialize biases into Detect(), cf is class frequency$/;"	m	class:Model
_initialize_biases	models/yolo.py	/^    def _initialize_biases(self, cf=None):  # initialize biases into Detect(), cf is class frequency$/;"	m	class:Model
_initialize_biases_bin	models/yolo.py	/^    def _initialize_biases_bin(self, cf=None):  # initialize biases into Detect(), cf is class frequency$/;"	m	class:Model
_initialize_biases_kpt	models/yolo.py	/^    def _initialize_biases_kpt(self, cf=None):  # initialize biases into Detect(), cf is class frequency$/;"	m	class:Model
_make_grid	models/yolo.py	/^    def _make_grid(nx=20, ny=20):$/;"	m	class:Detect
_make_grid	models/yolo.py	/^    def _make_grid(nx=20, ny=20):$/;"	m	class:IAuxDetect
_make_grid	models/yolo.py	/^    def _make_grid(nx=20, ny=20):$/;"	m	class:IBin
_make_grid	models/yolo.py	/^    def _make_grid(nx=20, ny=20):$/;"	m	class:IDetect
_make_grid	models/yolo.py	/^    def _make_grid(nx=20, ny=20):$/;"	m	class:IKeypoint
_pad_1x1_to_3x3_tensor	models/common.py	/^    def _pad_1x1_to_3x3_tensor(self, kernel1x1):$/;"	m	class:RepConv
_pad_1x1_to_3x3_tensor	models/common.py	/^    def _pad_1x1_to_3x3_tensor(self, kernel1x1):$/;"	m	class:RepConv_OREPA
_print_biases	models/yolo.py	/^    def _print_biases(self):$/;"	m	class:Model
aLRPLoss	utils/loss.py	/^class aLRPLoss(torch.autograd.Function):$/;"	c
accumulate	train.py	/^                accumulate = max(1, np.interp(ni, xi, [1, nbs \/ total_batch_size]).round())$/;"	v	class:train.names
accumulate	train_aux.py	/^                accumulate = max(1, np.interp(ni, xi, [1, nbs \/ total_batch_size]).round())$/;"	v	class:train.names
action	deploy/triton-inference-server/client.py	/^                        action="store_true",$/;"	v
after	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
after	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
aliases	train.py	/^                                            aliases=['last', 'best', 'stripped'])$/;"	v	class:train.names
aliases	train_aux.py	/^                                            aliases=['last', 'best', 'stripped'])$/;"	v	class:train.names
amp	models/common.py	/^from torch.cuda import amp$/;"	i
amp	train.py	/^from torch.cuda import amp$/;"	i
amp	train_aux.py	/^from torch.cuda import amp$/;"	i
anchor_fitness	utils/autoanchor.py	/^    def anchor_fitness(k):  # mutation fitness$/;"	f	function:kmean_anchors
ap_per_class	test.py	/^from utils.metrics import ap_per_class, ConfusionMatrix$/;"	i
ap_per_class	utils/metrics.py	/^def ap_per_class(tp, conf, pred_cls, target_cls, v5_metric=False, plot=False, save_dir='.', names=()):$/;"	f
apply_classifier	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
apply_classifier	utils/general.py	/^def apply_classifier(x, model, img, im0):$/;"	f
apriori	train.py	/^        apriori = opt.global_rank, opt.local_rank$/;"	v	class:train.names
apriori	train_aux.py	/^        apriori = opt.global_rank, opt.local_rank$/;"	v	class:train.names
argparse	deploy/triton-inference-server/client.py	/^import argparse$/;"	i
argparse	detect.py	/^import argparse$/;"	i
argparse	export.py	/^import argparse$/;"	i
argparse	models/yolo.py	/^import argparse$/;"	i
argparse	test.py	/^import argparse$/;"	i
argparse	train.py	/^import argparse$/;"	i
argparse	train_aux.py	/^import argparse$/;"	i
argparse	utils/wandb_logging/log_dataset.py	/^import argparse$/;"	i
attempt_download	hubconf.py	/^from utils.google_utils import attempt_download$/;"	i
attempt_download	models/experimental.py	/^from utils.google_utils import attempt_download$/;"	i
attempt_download	train.py	/^from utils.google_utils import attempt_download$/;"	i
attempt_download	train_aux.py	/^from utils.google_utils import attempt_download$/;"	i
attempt_download	utils/google_utils.py	/^def attempt_download(file, repo='WongKinYiu\/yolov7'):$/;"	f
attempt_load	detect.py	/^from models.experimental import attempt_load$/;"	i
attempt_load	export.py	/^from models.experimental import attempt_load, End2End$/;"	i
attempt_load	models/experimental.py	/^def attempt_load(weights, map_location=None):$/;"	f
attempt_load	test.py	/^from models.experimental import attempt_load$/;"	i
attempt_load	train.py	/^from models.experimental import attempt_load$/;"	i
attempt_load	train_aux.py	/^from models.experimental import attempt_load$/;"	i
augment_hsv	utils/datasets.py	/^def augment_hsv(img, hgain=0.5, sgain=0.5, vgain=0.5):$/;"	f
autoShape	models/common.py	/^class autoShape(nn.Module):$/;"	c
autopad	models/common.py	/^def autopad(k, p=None):  # kernel, padding$/;"	f
autoshape	models/common.py	/^    def autoshape(self):$/;"	m	class:autoShape
autoshape	models/yolo.py	/^    def autoshape(self):  # add autoShape module$/;"	m	class:Model
autosplit	utils/datasets.py	/^def autosplit(path='..\/coco', weights=(0.9, 0.1, 0.0), annotated_only=False):$/;"	f
backends	detect.py	/^import torch.backends.cudnn as cudnn$/;"	i
backends	utils/torch_utils.py	/^import torch.backends.cudnn as cudnn$/;"	i
backward	utils/activations.py	/^        def backward(ctx, grad_output):$/;"	m	class:MemoryEfficientMish.F
backward	utils/activations.py	/^        def backward(ctx, grad_output):$/;"	m	class:MemoryEfficientSwish.F
backward	utils/loss.py	/^    def backward(ctx, out_grad1):$/;"	m	class:APLoss
backward	utils/loss.py	/^    def backward(ctx, out_grad1, out_grad2):$/;"	m	class:RankSort
backward	utils/loss.py	/^    def backward(ctx, out_grad1, out_grad2, out_grad3):$/;"	m	class:aLRPLoss
batch_size	train.py	/^                                                 batch_size=batch_size * 2,$/;"	v	class:train.names
batch_size	train.py	/^                                          batch_size=batch_size * 2,$/;"	v	class:train.names
batch_size	train_aux.py	/^                                                 batch_size=batch_size * 2,$/;"	v	class:train.names
batch_size	train_aux.py	/^                                          batch_size=batch_size * 2,$/;"	v	class:train.names
bbox_alpha_iou	utils/general.py	/^def bbox_alpha_iou(box1, box2, x1y1x2y2=False, GIoU=False, DIoU=False, CIoU=False, alpha=2, eps=1e-9):$/;"	f
bbox_alpha_iou	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
bbox_ioa	utils/datasets.py	/^def bbox_ioa(box1, box2):$/;"	f
bbox_iou	utils/general.py	/^def bbox_iou(box1, box2, x1y1x2y2=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):$/;"	f
bbox_iou	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
best_fitness	train.py	/^                best_fitness = fi$/;"	v	class:train.names
best_fitness	train.py	/^            best_fitness = ckpt['best_fitness']$/;"	v	class:train.names
best_fitness	train_aux.py	/^                best_fitness = fi$/;"	v	class:train.names
best_fitness	train_aux.py	/^            best_fitness = ckpt['best_fitness']$/;"	v	class:train.names
box	deploy/triton-inference-server/boundingbox.py	/^    def box(self):$/;"	m	class:BoundingBox
box_area	utils/general.py	/^    def box_area(box):$/;"	f	function:box_ciou
box_area	utils/general.py	/^    def box_area(box):$/;"	f	function:box_diou
box_area	utils/general.py	/^    def box_area(box):$/;"	f	function:box_giou
box_area	utils/general.py	/^    def box_area(box):$/;"	f	function:box_iou
box_candidates	utils/datasets.py	/^def box_candidates(box1, box2, wh_thr=2, ar_thr=20, area_thr=0.1, eps=1e-16):  # box1(4,n), box2(4,n)$/;"	f
box_ciou	utils/general.py	/^def box_ciou(box1, box2, eps: float = 1e-7):$/;"	f
box_ciou	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
box_diou	utils/general.py	/^def box_diou(box1, box2, eps: float = 1e-7):$/;"	f
box_diou	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
box_giou	utils/general.py	/^def box_giou(box1, box2):$/;"	f
box_giou	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
box_iou	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
box_iou	utils/general.py	/^def box_iou(box1, box2):$/;"	f
box_iou	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
build_targets	utils/loss.py	/^    def build_targets(self, p, targets):$/;"	m	class:ComputeLoss
build_targets	utils/loss.py	/^    def build_targets(self, p, targets, imgs):$/;"	m	class:ComputeLossAuxOTA
build_targets	utils/loss.py	/^    def build_targets(self, p, targets, imgs):$/;"	m	class:ComputeLossBinOTA
build_targets	utils/loss.py	/^    def build_targets(self, p, targets, imgs):$/;"	m	class:ComputeLossOTA
build_targets2	utils/loss.py	/^    def build_targets2(self, p, targets, imgs):$/;"	m	class:ComputeLossAuxOTA
butter	utils/plots.py	/^from scipy.signal import butter, filtfilt$/;"	i
butter_lowpass	utils/plots.py	/^    def butter_lowpass(cutoff, fs, order):$/;"	f	function:butter_lowpass_filtfilt
butter_lowpass_filtfilt	utils/plots.py	/^def butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):$/;"	f
c	train.py	/^            c = torch.tensor(labels[:, 0])  # classes$/;"	v	class:train.names
c	train_aux.py	/^            c = torch.tensor(labels[:, 0])  # classes$/;"	v	class:train.names
cache_labels	utils/datasets.py	/^    def cache_labels(self, path=Path('.\/labels.cache'), prefix=''):$/;"	m	class:LoadImagesAndLabels
cap	deploy/triton-inference-server/client.py	/^        cap = cv2.VideoCapture(FLAGS.input)$/;"	v
center_absolute	deploy/triton-inference-server/boundingbox.py	/^    def center_absolute(self):$/;"	m	class:BoundingBox
center_normalized	deploy/triton-inference-server/boundingbox.py	/^    def center_normalized(self):$/;"	m	class:BoundingBox
certificate_chain	deploy/triton-inference-server/client.py	/^            certificate_chain=FLAGS.certificate_chain)$/;"	v
check_anchor_order	models/yolo.py	/^from utils.autoanchor import check_anchor_order$/;"	i
check_anchor_order	utils/autoanchor.py	/^def check_anchor_order(m):$/;"	f
check_anchors	train.py	/^from utils.autoanchor import check_anchors$/;"	i
check_anchors	train_aux.py	/^from utils.autoanchor import check_anchors$/;"	i
check_anchors	utils/autoanchor.py	/^def check_anchors(dataset, model, thr=4.0, imgsz=640):$/;"	f
check_and_upload_dataset	utils/wandb_logging/wandb_utils.py	/^    def check_and_upload_dataset(self, opt):$/;"	m	class:WandbLogger
check_dataset	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
check_dataset	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_dataset	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_dataset	utils/general.py	/^def check_dataset(dict):$/;"	f
check_dataset	utils/wandb_logging/wandb_utils.py	/^from utils.general import colorstr, xywh2xyxy, check_dataset$/;"	i
check_file	models/yolo.py	/^from utils.general import make_divisible, check_file, set_logging$/;"	i
check_file	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
check_file	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_file	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_file	utils/general.py	/^def check_file(file):$/;"	f
check_git_status	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_git_status	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_git_status	utils/general.py	/^def check_git_status():$/;"	f
check_img_size	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
check_img_size	export.py	/^from utils.general import set_logging, check_img_size$/;"	i
check_img_size	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
check_img_size	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_img_size	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_img_size	utils/general.py	/^def check_img_size(img_size, s=32):$/;"	f
check_imshow	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
check_imshow	utils/general.py	/^def check_imshow():$/;"	f
check_online	utils/general.py	/^def check_online():$/;"	f
check_requirements	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
check_requirements	hubconf.py	/^from utils.general import check_requirements, set_logging$/;"	i
check_requirements	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
check_requirements	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_requirements	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
check_requirements	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
check_requirements	utils/general.py	/^def check_requirements(requirements='requirements.txt', exclude=()):$/;"	f
check_wandb_config_file	utils/wandb_logging/wandb_utils.py	/^def check_wandb_config_file(data_config_file):$/;"	f
check_wandb_resume	train.py	/^from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume$/;"	i
check_wandb_resume	train_aux.py	/^from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume$/;"	i
check_wandb_resume	utils/wandb_logging/wandb_utils.py	/^def check_wandb_resume(opt):$/;"	f
choices	deploy/triton-inference-server/client.py	/^                        choices=['dummy', 'image', 'video'],$/;"	v
ckpt	train.py	/^                ckpt = {'epoch': epoch,$/;"	v	class:train.names
ckpt	train.py	/^        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path$/;"	v	class:train.names
ckpt	train.py	/^        ckpt = torch.load(weights, map_location=device)  # load checkpoint$/;"	v	class:train.names
ckpt	train_aux.py	/^                ckpt = {'epoch': epoch,$/;"	v	class:train.names
ckpt	train_aux.py	/^        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path$/;"	v	class:train.names
ckpt	train_aux.py	/^        ckpt = torch.load(weights, map_location=device)  # load checkpoint$/;"	v	class:train.names
ckpt	utils/aws/resume.py	/^    ckpt = torch.load(last)$/;"	v
classes	models/common.py	/^    classes = None  # (optional list) filter by class$/;"	v	class:NMS
classes	models/common.py	/^    classes = None  # (optional list) filter by class$/;"	v	class:autoShape
clean_str	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
clean_str	utils/general.py	/^def clean_str(s):$/;"	f
client_timeout	deploy/triton-inference-server/client.py	/^                                          client_timeout=FLAGS.client_timeout)$/;"	v
client_timeout	deploy/triton-inference-server/client.py	/^                                      client_timeout=FLAGS.client_timeout)$/;"	v
clip_coords	utils/general.py	/^def clip_coords(boxes, img_shape):$/;"	f
cmd	utils/aws/resume.py	/^        cmd = f'python -m torch.distributed.launch --nproc_per_node {nd} --master_port {port} train.py --resume {last}'$/;"	v
cmd	utils/aws/resume.py	/^        cmd = f'python train.py --resume {last}'$/;"	v
coco80_to_coco91_class	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
coco80_to_coco91_class	utils/general.py	/^def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)$/;"	f
collate_fn	utils/datasets.py	/^    def collate_fn(batch):$/;"	m	class:LoadImagesAndLabels
collate_fn4	utils/datasets.py	/^    def collate_fn4(batch):$/;"	m	class:LoadImagesAndLabels
color_list	models/common.py	/^from utils.plots import color_list, plot_one_box$/;"	i
color_list	utils/plots.py	/^def color_list():$/;"	f
colorstr	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
colorstr	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
colorstr	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
colorstr	utils/autoanchor.py	/^from utils.general import colorstr$/;"	i
colorstr	utils/general.py	/^def colorstr(*input):$/;"	f
colorstr	utils/wandb_logging/wandb_utils.py	/^from utils.general import colorstr, xywh2xyxy, check_dataset$/;"	i
computation	models/yolo.py	/^    import thop  # for FLOPS computation$/;"	i
computation	utils/torch_utils.py	/^    import thop  # for FLOPS computation$/;"	i
compute_ap	utils/metrics.py	/^def compute_ap(recall, precision, v5_metric=False):$/;"	f
compute_loss	train.py	/^                                                 compute_loss=compute_loss,$/;"	v	class:train.names
compute_loss	train_aux.py	/^                                                 compute_loss=compute_loss,$/;"	v	class:train.names
concat	models/yolo.py	/^    concat = False$/;"	v	class:Detect
concat	models/yolo.py	/^    concat = False$/;"	v	class:IAuxDetect
concat	models/yolo.py	/^    concat = False$/;"	v	class:IDetect
conf	models/common.py	/^    conf = 0.25  # NMS confidence threshold$/;"	v	class:autoShape
conf	models/common.py	/^    conf = 0.25  # confidence threshold$/;"	v	class:NMS
conf_thres	train.py	/^                                          conf_thres=0.001,$/;"	v	class:train.names
conf_thres	train_aux.py	/^                                          conf_thres=0.001,$/;"	v	class:train.names
config	deploy/triton-inference-server/client.py	/^            config = triton_client.get_model_config(FLAGS.model)$/;"	v
contextmanager	utils/torch_utils.py	/^from contextlib import contextmanager$/;"	i
convert	models/yolo.py	/^    def convert(self, z):$/;"	m	class:Detect
convert	models/yolo.py	/^    def convert(self, z):$/;"	m	class:IAuxDetect
convert	models/yolo.py	/^    def convert(self, z):$/;"	m	class:IDetect
copy	models/common.py	/^from copy import copy$/;"	i
copy	utils/plots.py	/^from copy import copy$/;"	i
copy_attr	models/yolo.py	/^    select_device, copy_attr$/;"	i
copy_attr	utils/torch_utils.py	/^def copy_attr(a, b, include=(), exclude=()):$/;"	f
copy_paste	utils/datasets.py	/^def copy_paste(img, labels, segments, probability=0.5):$/;"	f
counter	deploy/triton-inference-server/client.py	/^        counter = 0$/;"	v
create	hubconf.py	/^def create(name, pretrained, channels, classes, autoshape):$/;"	f
create_dataloader	test.py	/^from utils.datasets import create_dataloader$/;"	i
create_dataloader	train.py	/^from utils.datasets import create_dataloader$/;"	i
create_dataloader	train_aux.py	/^from utils.datasets import create_dataloader$/;"	i
create_dataloader	utils/datasets.py	/^def create_dataloader(path, imgsz, batch_size, stride, opt, hyp=None, augment=False, cache=False, pad=0.0, rect=False,$/;"	f
create_dataset_artifact	utils/wandb_logging/log_dataset.py	/^def create_dataset_artifact(opt):$/;"	f
create_dataset_table	utils/wandb_logging/wandb_utils.py	/^    def create_dataset_table(self, dataset, class_to_id, name='dataset'):$/;"	m	class:WandbLogger
create_folder	utils/datasets.py	/^def create_folder(path='.\/new'):$/;"	f
create_mask	models/common.py	/^    def create_mask(self, H, W):$/;"	m	class:SwinTransformerLayer
create_mask	models/common.py	/^    def create_mask(self, H, W):$/;"	m	class:SwinTransformerLayer_v2
ct	export.py	/^        import coremltools as ct$/;"	i
ct_model	export.py	/^                    ct_model = ct.models.neural_network.quantization_utils.quantize_weights(ct_model, bits, mode)$/;"	v
ct_model	export.py	/^        ct_model = ct.convert(ts, inputs=[ct.ImageType('image', shape=img.shape, scale=1 \/ 255.0, bias=[0, 0, 0])])$/;"	v
cudnn	detect.py	/^import torch.backends.cudnn as cudnn$/;"	i
cudnn	utils/torch_utils.py	/^import torch.backends.cudnn as cudnn$/;"	i
custom	hubconf.py	/^def custom(path_or_model='path\/to\/model.pt', autoshape=True):$/;"	f
cutout	utils/datasets.py	/^def cutout(image, labels):$/;"	f
cv2	deploy/triton-inference-server/client.py	/^import cv2$/;"	i
cv2	deploy/triton-inference-server/processing.py	/^import cv2$/;"	i
cv2	deploy/triton-inference-server/render.py	/^import cv2$/;"	i
cv2	detect.py	/^import cv2$/;"	i
cv2	utils/datasets.py	/^import cv2$/;"	i
cv2	utils/general.py	/^import cv2$/;"	i
cv2	utils/plots.py	/^import cv2$/;"	i
cw	train.py	/^                cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 \/ nc  # class weights$/;"	v	class:train.names
cw	train_aux.py	/^                cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 \/ nc  # class weights$/;"	v	class:train.names
d	utils/aws/resume.py	/^    d = opt['device'].split(',')  # devices$/;"	v
data	train.py	/^import torch.utils.data$/;"	i
data	train_aux.py	/^import torch.utils.data$/;"	i
dataloader	train.py	/^                                                 dataloader=testloader,$/;"	v	class:train.names
dataloader	train.py	/^                                          dataloader=testloader,$/;"	v	class:train.names
dataloader	train_aux.py	/^                                                 dataloader=testloader,$/;"	v	class:train.names
dataloader	train_aux.py	/^                                          dataloader=testloader,$/;"	v	class:train.names
date_modified	utils/torch_utils.py	/^def date_modified(path=__file__):$/;"	f
datetime	utils/torch_utils.py	/^import datetime$/;"	i
ddp	utils/aws/resume.py	/^    ddp = nd > 1 or (nd == 0 and torch.cuda.device_count() > 1)  # distributed data parallel$/;"	v
deepcopy	models/yolo.py	/^from copy import deepcopy$/;"	i
deepcopy	train.py	/^from copy import deepcopy$/;"	i
deepcopy	train_aux.py	/^from copy import deepcopy$/;"	i
deepcopy	utils/datasets.py	/^from copy import deepcopy$/;"	i
deepcopy	utils/torch_utils.py	/^from copy import deepcopy$/;"	i
default	deploy/triton-inference-server/client.py	/^                        default='',$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default='dummy',$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default='localhost:8001',$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default='yolov7',$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default=24.0,$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default=640,$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default=False,$/;"	v
default	deploy/triton-inference-server/client.py	/^                        default=None,$/;"	v
dependencies	hubconf.py	/^dependencies = ['torch', 'yaml']$/;"	v
det_boxes	deploy/triton-inference-server/client.py	/^            det_boxes = results.as_numpy("det_boxes")$/;"	v
det_boxes	deploy/triton-inference-server/client.py	/^        det_boxes = results.as_numpy(OUTPUT_NAMES[1])$/;"	v
det_classes	deploy/triton-inference-server/client.py	/^            det_classes = results.as_numpy("det_classes")$/;"	v
det_classes	deploy/triton-inference-server/client.py	/^        det_classes = results.as_numpy(OUTPUT_NAMES[3])$/;"	v
det_scores	deploy/triton-inference-server/client.py	/^            det_scores = results.as_numpy("det_scores")$/;"	v
det_scores	deploy/triton-inference-server/client.py	/^        det_scores = results.as_numpy(OUTPUT_NAMES[2])$/;"	v
detect	detect.py	/^def detect(save_img=False):$/;"	f
detected_objects	deploy/triton-inference-server/client.py	/^            detected_objects = postprocess(num_dets, det_boxes, det_scores, det_classes, frame.shape[1], frame.shape[0], [FLAGS.width, FLAGS.height])$/;"	v
detected_objects	deploy/triton-inference-server/client.py	/^        detected_objects = postprocess(num_dets, det_boxes, det_scores, det_classes, input_image.shape[1], input_image.shape[0], [FLAGS.width, FLAGS.height])$/;"	v
detections	utils/general.py	/^            x[i] = x[i][pred_cls1 == pred_cls2]  # retain matching class detections$/;"	c	function:apply_classifier
device	export.py	/^    device = select_device(opt.device)$/;"	v
device	models/yolo.py	/^    device = select_device(opt.device)$/;"	v
device	train.py	/^        device = torch.device('cuda', opt.local_rank)$/;"	v	class:train.names
device	train_aux.py	/^        device = torch.device('cuda', opt.local_rank)$/;"	v	class:train.names
display	models/common.py	/^    def display(self, pprint=False, show=False, save=False, render=False, save_dir=''):$/;"	m	class:Detections
dist	train.py	/^import torch.distributed as dist$/;"	i
dist	train_aux.py	/^import torch.distributed as dist$/;"	i
download_dataset_artifact	utils/wandb_logging/wandb_utils.py	/^    def download_dataset_artifact(self, path, alias):$/;"	m	class:WandbLogger
download_model_artifact	utils/wandb_logging/wandb_utils.py	/^    def download_model_artifact(self, opt):$/;"	m	class:WandbLogger
dwsc2full	models/common.py	/^    def dwsc2full(self, weight_dw, weight_pw, groups):$/;"	m	class:OREPA_3x3_RepConv
dynamic_axes	export.py	/^                          dynamic_axes=dynamic_axes)$/;"	v
dynamic_axes	export.py	/^            dynamic_axes = {$/;"	v
dynamic_axes	export.py	/^            dynamic_axes = {'images': {0: 'batch', 2: 'height', 3: 'width'},  # size(1,3,640,640)$/;"	v
dynamic_axes	export.py	/^        dynamic_axes = None$/;"	v
each	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
each	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
emojis	utils/general.py	/^def emojis(str=''):$/;"	f
end2end	models/yolo.py	/^    end2end = False$/;"	v	class:Detect
end2end	models/yolo.py	/^    end2end = False$/;"	v	class:IAuxDetect
end2end	models/yolo.py	/^    end2end = False$/;"	v	class:IDetect
end_epoch	utils/wandb_logging/wandb_utils.py	/^    def end_epoch(self, best_result=False):$/;"	m	class:WandbLogger
epoch	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
epoch	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
exclude	train.py	/^        exclude = ['anchor'] if (opt.cfg or hyp.get('anchors')) and not opt.resume else []  # exclude keys$/;"	v	class:train.names
exclude	train_aux.py	/^        exclude = ['anchor'] if (opt.cfg or hyp.get('anchors')) and not opt.resume else []  # exclude keys$/;"	v	class:train.names
exif_size	utils/datasets.py	/^def exif_size(img):$/;"	f
export	models/yolo.py	/^    export = False  # onnx export$/;"	v	class:Detect
export	models/yolo.py	/^    export = False  # onnx export$/;"	v	class:IAuxDetect
export	models/yolo.py	/^    export = False  # onnx export$/;"	v	class:IBin
export	models/yolo.py	/^    export = False  # onnx export$/;"	v	class:IDetect
export	models/yolo.py	/^    export = False  # onnx export$/;"	v	class:IKeypoint
export	utils/loss.py	/^    export = False  # onnx export$/;"	v	class:SigmoidBin
extra_repr	models/common.py	/^    def extra_repr(self) -> str:$/;"	m	class:SwinTransformerLayer_v2
extra_repr	models/common.py	/^    def extra_repr(self) -> str:$/;"	m	class:WindowAttention_v2
extract_boxes	utils/datasets.py	/^def extract_boxes(path='..\/coco\/'):  # from utils.datasets import *; extract_boxes('..\/coco128')$/;"	f
f	export.py	/^        f = opt.weights.replace('.pt', '.mlmodel')  # filename$/;"	v
f	export.py	/^        f = opt.weights.replace('.pt', '.onnx')  # filename$/;"	v
f	export.py	/^        f = opt.weights.replace('.pt', '.torchscript.pt')  # filename$/;"	v
f	export.py	/^        f = opt.weights.replace('.pt', '.torchscript.ptl')  # filename$/;"	v
f	test.py	/^            f = f'study_{Path(opt.data).stem}_{Path(w).stem}.txt'  # filename to save to$/;"	v
f	train.py	/^                    f = save_dir \/ f'train_batch{ni}.jpg'  # filename$/;"	v	class:train.names
f	train_aux.py	/^                    f = save_dir \/ f'train_batch{ni}.jpg'  # filename$/;"	v	class:train.names
fi	train.py	/^            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]$/;"	v	class:train.names
fi	train_aux.py	/^            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]$/;"	v	class:train.names
files	train.py	/^                files = ['results.png', 'confusion_matrix.png', *[f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R')]]$/;"	v	class:train.names
files	train_aux.py	/^                files = ['results.png', 'confusion_matrix.png', *[f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R')]]$/;"	v	class:train.names
filtfilt	utils/plots.py	/^from scipy.signal import butter, filtfilt$/;"	i
final	train.py	/^        final = best if best.exists() else last  # final model$/;"	v	class:train.names
final	train_aux.py	/^        final = best if best.exists() else last  # final model$/;"	v	class:train.names
find_3_positive	utils/loss.py	/^    def find_3_positive(self, p, targets):$/;"	m	class:ComputeLossAuxOTA
find_3_positive	utils/loss.py	/^    def find_3_positive(self, p, targets):$/;"	m	class:ComputeLossBinOTA
find_3_positive	utils/loss.py	/^    def find_3_positive(self, p, targets):$/;"	m	class:ComputeLossOTA
find_5_positive	utils/loss.py	/^    def find_5_positive(self, p, targets):$/;"	m	class:ComputeLossAuxOTA
find_modules	utils/torch_utils.py	/^def find_modules(model, mclass=nn.Conv2d):$/;"	f
find_unused_parameters	train.py	/^                    find_unused_parameters=any(isinstance(layer, nn.MultiheadAttention) for layer in model.modules()))$/;"	v	class:train.names
find_unused_parameters	train_aux.py	/^                    find_unused_parameters=any(isinstance(layer, nn.MultiheadAttention) for layer in model.modules()))$/;"	v	class:train.names
finish	utils/wandb_logging/wandb_utils.py	/^    from wandb import init, finish$/;"	i
finish_run	utils/wandb_logging/wandb_utils.py	/^    def finish_run(self):$/;"	m	class:WandbLogger
fitness	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
fitness	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
fitness	utils/general.py	/^from utils.metrics import fitness$/;"	i
fitness	utils/metrics.py	/^def fitness(x):$/;"	f
fitness	utils/plots.py	/^from utils.metrics import fitness$/;"	i
flatten_recursive	utils/datasets.py	/^def flatten_recursive(path='..\/coco'):$/;"	f
flops	models/common.py	/^    def flops(self):$/;"	m	class:SwinTransformerLayer_v2
flops	models/common.py	/^    def flops(self, N):$/;"	m	class:WindowAttention_v2
for	models/yolo.py	/^            import yaml  # for torch hub$/;"	i
for	models/yolo.py	/^    import thop  # for FLOPS computation$/;"	i
for	utils/torch_utils.py	/^    import thop  # for FLOPS computation$/;"	i
forward	models/common.py	/^    def forward(self, imgs, size=640, augment=False, profile=False):$/;"	m	class:autoShape
forward	models/common.py	/^    def forward(self, inputs):$/;"	m	class:OREPA_3x3_RepConv
forward	models/common.py	/^    def forward(self, inputs):$/;"	m	class:RepConv
forward	models/common.py	/^    def forward(self, inputs):$/;"	m	class:RepConv_OREPA
forward	models/common.py	/^    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w\/2,h\/2)$/;"	m	class:Focus
forward	models/common.py	/^    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w\/2,h\/2)$/;"	m	class:ReOrg
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Bottleneck
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:BottleneckCSPA
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:BottleneckCSPB
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:BottleneckCSPC
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Chuncat
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Classify
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Concat
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Contract
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Conv
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:ConvBN
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:DownC
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Expand
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Foldcut
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Ghost
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:GhostConv
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:ImplicitA
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:ImplicitM
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:MP
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Mlp
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Mlp_v2
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:NMS
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Res
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:RobustConv
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:RobustConv2
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SP
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SPP
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SPPCSPC
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SPPF
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:ST2CSPA
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:ST2CSPB
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:ST2CSPC
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:STCSPA
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:STCSPB
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:STCSPC
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Shortcut
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:Stem
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SwinTransformer2Block
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SwinTransformerBlock
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SwinTransformerLayer
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:SwinTransformerLayer_v2
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:TransformerBlock
forward	models/common.py	/^    def forward(self, x):$/;"	m	class:TransformerLayer
forward	models/common.py	/^    def forward(self, x, mask=None):$/;"	m	class:WindowAttention
forward	models/common.py	/^    def forward(self, x, mask=None):$/;"	m	class:WindowAttention_v2
forward	models/experimental.py	/^    def forward($/;"	m	class:TRT_NMS
forward	models/experimental.py	/^    def forward(ctx,$/;"	m	class:ORT_NMS
forward	models/experimental.py	/^    def forward(self, x):$/;"	m	class:CrossConv
forward	models/experimental.py	/^    def forward(self, x):$/;"	m	class:End2End
forward	models/experimental.py	/^    def forward(self, x):$/;"	m	class:MixConv2d
forward	models/experimental.py	/^    def forward(self, x):$/;"	m	class:ONNX_ORT
forward	models/experimental.py	/^    def forward(self, x):$/;"	m	class:ONNX_TRT
forward	models/experimental.py	/^    def forward(self, x):$/;"	m	class:Sum
forward	models/experimental.py	/^    def forward(self, x, augment=False):$/;"	m	class:Ensemble
forward	models/yolo.py	/^    def forward(self, x):$/;"	m	class:Detect
forward	models/yolo.py	/^    def forward(self, x):$/;"	m	class:IAuxDetect
forward	models/yolo.py	/^    def forward(self, x):$/;"	m	class:IBin
forward	models/yolo.py	/^    def forward(self, x):$/;"	m	class:IDetect
forward	models/yolo.py	/^    def forward(self, x):$/;"	m	class:IKeypoint
forward	models/yolo.py	/^    def forward(self, x, augment=False, profile=False):$/;"	m	class:Model
forward	utils/activations.py	/^        def forward(ctx, x):$/;"	m	class:MemoryEfficientMish.F
forward	utils/activations.py	/^        def forward(ctx, x):$/;"	m	class:MemoryEfficientSwish.F
forward	utils/activations.py	/^    def forward(self, x):$/;"	m	class:FReLU
forward	utils/activations.py	/^    def forward(self, x):$/;"	m	class:MemoryEfficientMish
forward	utils/activations.py	/^    def forward(self, x):$/;"	m	class:MemoryEfficientSwish
forward	utils/activations.py	/^    def forward(x):$/;"	m	class:Hardswish
forward	utils/activations.py	/^    def forward(x):$/;"	m	class:Mish
forward	utils/activations.py	/^    def forward(x):$/;"	m	class:SiLU
forward	utils/loss.py	/^    def forward(ctx, logits, targets, delta=1.): $/;"	m	class:APLoss
forward	utils/loss.py	/^    def forward(ctx, logits, targets, delta_RS=0.50, eps=1e-10): $/;"	m	class:RankSort
forward	utils/loss.py	/^    def forward(ctx, logits, targets, regression_losses, delta=1., eps=1e-5): $/;"	m	class:aLRPLoss
forward	utils/loss.py	/^    def forward(self, pred):$/;"	m	class:SigmoidBin
forward	utils/loss.py	/^    def forward(self, pred, true):$/;"	m	class:BCEBlurWithLogitsLoss
forward	utils/loss.py	/^    def forward(self, pred, true):$/;"	m	class:FocalLoss
forward	utils/loss.py	/^    def forward(self, pred, true):$/;"	m	class:QFocalLoss
forward	utils/torch_utils.py	/^    def forward(self, x, augment=False, profile=False):$/;"	m	class:TracedModel
forward_once	models/yolo.py	/^    def forward_once(self, x, profile=False):$/;"	m	class:Model
fourcc	deploy/triton-inference-server/client.py	/^                fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')$/;"	v
frame	deploy/triton-inference-server/client.py	/^                frame = render_box(frame, box.box(), color=tuple(RAND_COLORS[box.classID % 64].tolist()))$/;"	v
frame	deploy/triton-inference-server/client.py	/^                frame = render_filled_box(frame, (box.x1 - 3, box.y1 - 3, box.x1 + size[0], box.y1 + size[1]), color=(220, 220, 220))$/;"	v
frame	deploy/triton-inference-server/client.py	/^                frame = render_text(frame, f"{COCOLabels(box.classID).name}: {box.confidence:.2f}", (box.x1, box.y1), color=(30, 30, 30), normalised_scaling=0.5)$/;"	v
fre_init	models/common.py	/^    def fre_init(self):$/;"	m	class:OREPA_3x3_RepConv
fuse	models/yolo.py	/^    def fuse(self):  # fuse model Conv2d() + BatchNorm2d() layers$/;"	m	class:Model
fuse	models/yolo.py	/^    def fuse(self):$/;"	m	class:IAuxDetect
fuse	models/yolo.py	/^    def fuse(self):$/;"	m	class:IDetect
fuse_conv_and_bn	models/yolo.py	/^    select_device, copy_attr$/;"	i
fuse_conv_and_bn	utils/torch_utils.py	/^def fuse_conv_and_bn(conv, bn):$/;"	f
fuse_conv_bn	models/common.py	/^    def fuse_conv_bn(self, conv, bn):$/;"	m	class:RepConv
fuse_repvgg_block	models/common.py	/^    def fuse_repvgg_block(self):    $/;"	m	class:RepConv
fuseforward	models/common.py	/^    def fuseforward(self, x):$/;"	m	class:Conv
fuseforward	models/yolo.py	/^    def fuseforward(self, x):$/;"	m	class:IAuxDetect
fuseforward	models/yolo.py	/^    def fuseforward(self, x):$/;"	m	class:IDetect
g	train.py	/^                g = np.array([x[0] for x in meta.values()])  # gains 0-1$/;"	v	class:train.names
g	train_aux.py	/^                g = np.array([x[0] for x in meta.values()])  # gains 0-1$/;"	v	class:train.names
gdrive_download	utils/google_utils.py	/^def gdrive_download(id='', file='tmp.zip'):$/;"	f
general	utils/metrics.py	/^from . import general$/;"	i
get	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
get	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
get_custom_L2	models/common.py	/^    def get_custom_L2(self):$/;"	m	class:RepConv_OREPA
get_equivalent_kernel_bias	models/common.py	/^    def get_equivalent_kernel_bias(self):$/;"	m	class:RepConv
get_equivalent_kernel_bias	models/common.py	/^    def get_equivalent_kernel_bias(self):$/;"	m	class:RepConv_OREPA
get_hash	utils/datasets.py	/^def get_hash(files):$/;"	f
get_latest_run	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
get_latest_run	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
get_latest_run	utils/general.py	/^def get_latest_run(search_dir='.'):$/;"	f
get_length	utils/loss.py	/^    def get_length(self):$/;"	m	class:SigmoidBin
get_run_info	utils/wandb_logging/wandb_utils.py	/^def get_run_info(run_path):$/;"	f
get_text_size	deploy/triton-inference-server/client.py	/^from render import render_box, render_filled_box, get_text_size, render_text, RAND_COLORS$/;"	i
get_text_size	deploy/triton-inference-server/render.py	/^def get_text_size(img, text, normalised_scaling=1.0):$/;"	f
get_token	utils/google_utils.py	/^def get_token(cookie=".\/cookie"):$/;"	f
git_describe	utils/torch_utils.py	/^def git_describe(path=Path(__file__).parent):  # path must be a directory$/;"	f
glob	utils/datasets.py	/^import glob$/;"	i
glob	utils/general.py	/^import glob$/;"	i
glob	utils/plots.py	/^import glob$/;"	i
grpcclient	deploy/triton-inference-server/client.py	/^import tritonclient.grpc as grpcclient$/;"	i
gs	export.py	/^    gs = int(max(model.stride))  # grid size (max stride)$/;"	v
gs	utils/add_nms.py	/^    import onnx_graphsurgeon as gs$/;"	i
gsutil_getsize	utils/general.py	/^from utils.google_utils import gsutil_getsize$/;"	i
gsutil_getsize	utils/google_utils.py	/^def gsutil_getsize(url=''):$/;"	f
height	deploy/triton-inference-server/boundingbox.py	/^    def height(self):$/;"	m	class:BoundingBox
help	deploy/triton-inference-server/client.py	/^                        help='Client timeout in seconds, default no timeout')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Enable SSL encrypted channel to the server')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Enable verbose client output')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='File holding PEM-encoded certicate chain default is none')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='File holding PEM-encoded private key, default is none')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='File holding PEM-encoded root certificates, default none')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Inference model input height, default 640')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Inference model input width, default 640')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Inference model name, default yolov7')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Inference server URL, default localhost:8001')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Input file to load from in image or video mode')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Print model status, configuration and statistics')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Run mode. \\'dummy\\' will send an emtpy buffer to the server to test if inference works. \\'image\\' will process an image. \\'video\\' will process a video.')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Video output fps, default 24.0 FPS')$/;"	v
help	deploy/triton-inference-server/client.py	/^                        help='Write output into file instead of displaying it')$/;"	v
help_url	utils/datasets.py	/^help_url = 'https:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data'$/;"	v
hex2rgb	utils/plots.py	/^    def hex2rgb(h):$/;"	f	function:color_list
hist2d	utils/plots.py	/^def hist2d(x, y, n=100):$/;"	f
hist_equalize	utils/datasets.py	/^def hist_equalize(img, clahe=True, bgr=False):$/;"	f
hub	models/yolo.py	/^            import yaml  # for torch hub$/;"	i
hub_model	hubconf.py	/^        hub_model = hub_model.autoshape()  # for file\/URI\/PIL\/cv2\/np inputs and NMS$/;"	v	class:custom.names
hyp	train.py	/^            hyp = yaml.safe_load(f)  # load hyps dict$/;"	v	class:train.names
hyp	train.py	/^        hyp = yaml.load(f, Loader=yaml.SafeLoader)  # load hyps$/;"	v	class:train.names
hyp	train_aux.py	/^            hyp = yaml.safe_load(f)  # load hyps dict$/;"	v	class:train.names
hyp	train_aux.py	/^        hyp = yaml.load(f, Loader=yaml.SafeLoader)  # load hyps$/;"	v	class:train.names
i	utils/general.py	/^                i = i[iou.sum(1) > 1]  # require redundancy$/;"	v	class:non_max_suppression.only
i	utils/general.py	/^                i = i[iou.sum(1) > 1]  # require redundancy$/;"	v	class:non_max_suppression_kpt.only
i	utils/general.py	/^            i = i[:max_det]$/;"	v	class:non_max_suppression.only
i	utils/general.py	/^            i = i[:max_det]$/;"	v	class:non_max_suppression_kpt.only
img	export.py	/^    img = torch.zeros(opt.batch_size, 3, *opt.img_size).to(device)  # image size(1,3,320,192) iDetection$/;"	v
img	models/yolo.py	/^        img = torch.rand(1, 3, 640, 640).to(device)$/;"	v
img2label_paths	utils/datasets.py	/^def img2label_paths(img_paths):$/;"	f
img2label_paths	utils/wandb_logging/wandb_utils.py	/^from utils.datasets import img2label_paths$/;"	i
img_formats	utils/datasets.py	/^img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes$/;"	v
imgs	train.py	/^                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)$/;"	v	class:train.names
imgs	train.py	/^            imgs = imgs.to(device, non_blocking=True).float() \/ 255.0  # uint8 to float32, 0-255 to 0.0-1.0$/;"	v	class:train.names
imgs	train_aux.py	/^                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)$/;"	v	class:train.names
imgs	train_aux.py	/^            imgs = imgs.to(device, non_blocking=True).float() \/ 255.0  # uint8 to float32, 0-255 to 0.0-1.0$/;"	v	class:train.names
imgsz	train.py	/^                                                 imgsz=imgsz_test,$/;"	v	class:train.names
imgsz	train.py	/^                                          imgsz=imgsz_test,$/;"	v	class:train.names
imgsz	train_aux.py	/^                                                 imgsz=imgsz_test,$/;"	v	class:train.names
imgsz	train_aux.py	/^                                          imgsz=imgsz_test,$/;"	v	class:train.names
import	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
import	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
include_nms	models/yolo.py	/^    include_nms = False$/;"	v	class:Detect
include_nms	models/yolo.py	/^    include_nms = False$/;"	v	class:IAuxDetect
include_nms	models/yolo.py	/^    include_nms = False$/;"	v	class:IDetect
increment_path	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
increment_path	models/common.py	/^from utils.general import non_max_suppression, make_divisible, scale_coords, increment_path, xyxy2xywh$/;"	i
increment_path	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
increment_path	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
increment_path	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
increment_path	utils/general.py	/^def increment_path(path, exist_ok=True, sep=''):$/;"	f
indices	train.py	/^                indices = (torch.tensor(dataset.indices) if rank == 0 else torch.zeros(dataset.n)).int()$/;"	v	class:train.names
indices	train_aux.py	/^                indices = (torch.tensor(dataset.indices) if rank == 0 else torch.zeros(dataset.n)).int()$/;"	v	class:train.names
infer	utils/add_nms.py	/^    def infer(self):$/;"	m	class:RegisterNMS
info	models/yolo.py	/^    def info(self, verbose=False, img_size=640):  # print model information$/;"	m	class:Model
init	utils/wandb_logging/wandb_utils.py	/^    from wandb import init, finish$/;"	i
init_seeds	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
init_seeds	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
init_seeds	utils/general.py	/^def init_seeds(seed=0):$/;"	f
init_torch_seeds	utils/general.py	/^from utils.torch_utils import init_torch_seeds$/;"	i
init_torch_seeds	utils/torch_utils.py	/^def init_torch_seeds(seed=0):$/;"	f
initialize_weights	models/yolo.py	/^    select_device, copy_attr$/;"	i
initialize_weights	utils/torch_utils.py	/^def initialize_weights(model):$/;"	f
input_image	deploy/triton-inference-server/client.py	/^            input_image = render_box(input_image, box.box(), color=tuple(RAND_COLORS[box.classID % 64].tolist()))$/;"	v
input_image	deploy/triton-inference-server/client.py	/^            input_image = render_filled_box(input_image, (box.x1 - 3, box.y1 - 3, box.x1 + size[0], box.y1 + size[1]), color=(220, 220, 220))$/;"	v
input_image	deploy/triton-inference-server/client.py	/^            input_image = render_text(input_image, f"{COCOLabels(box.classID).name}: {box.confidence:.2f}", (box.x1, box.y1), color=(30, 30, 30), normalised_scaling=0.5)$/;"	v
input_image	deploy/triton-inference-server/client.py	/^        input_image = cv2.imread(str(FLAGS.input))$/;"	v
input_image_buffer	deploy/triton-inference-server/client.py	/^            input_image_buffer = np.expand_dims(input_image_buffer, axis=0)$/;"	v
input_image_buffer	deploy/triton-inference-server/client.py	/^            input_image_buffer = preprocess(frame, [FLAGS.width, FLAGS.height])$/;"	v
input_image_buffer	deploy/triton-inference-server/client.py	/^        input_image_buffer = np.expand_dims(input_image_buffer, axis=0)$/;"	v
input_image_buffer	deploy/triton-inference-server/client.py	/^        input_image_buffer = preprocess(input_image, [FLAGS.width, FLAGS.height])$/;"	v
inputs	deploy/triton-inference-server/client.py	/^                                          inputs=inputs,$/;"	v
inputs	deploy/triton-inference-server/client.py	/^                                      inputs=inputs,$/;"	v
inputs	deploy/triton-inference-server/client.py	/^        inputs = []$/;"	v
intersect_dicts	train.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
intersect_dicts	train_aux.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
intersect_dicts	utils/torch_utils.py	/^def intersect_dicts(da, db, exclude=()):$/;"	f
iou	models/common.py	/^    iou = 0.45  # IoU threshold$/;"	v	class:NMS
iou	models/common.py	/^    iou = 0.45  # NMS IoU threshold$/;"	v	class:autoShape
iou	utils/general.py	/^            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix$/;"	v	class:non_max_suppression.only
iou	utils/general.py	/^            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix$/;"	v	class:non_max_suppression_kpt.only
iou_thres	train.py	/^                                          iou_thres=0.7,$/;"	v	class:train.names
iou_thres	train_aux.py	/^                                          iou_thres=0.7,$/;"	v	class:train.names
is_coco	train.py	/^                                                 is_coco=is_coco,$/;"	v	class:train.names
is_coco	train.py	/^                                          is_coco=is_coco,$/;"	v	class:train.names
is_coco	train_aux.py	/^                                                 is_coco=is_coco,$/;"	v	class:train.names
is_coco	train_aux.py	/^                                          is_coco=is_coco,$/;"	v	class:train.names
is_parallel	train.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
is_parallel	train_aux.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
is_parallel	utils/loss.py	/^from utils.torch_utils import is_parallel$/;"	i
is_parallel	utils/torch_utils.py	/^def is_parallel(model):$/;"	f
isdocker	utils/general.py	/^def isdocker():$/;"	f
iw	train.py	/^                iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights$/;"	v	class:train.names
iw	train_aux.py	/^                iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights$/;"	v	class:train.names
json	test.py	/^import json$/;"	i
json	utils/wandb_logging/wandb_utils.py	/^import json$/;"	i
kmean_anchors	utils/autoanchor.py	/^def kmean_anchors(path='.\/data\/coco.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):$/;"	f
kmeans	utils/autoanchor.py	/^from scipy.cluster.vq import kmeans$/;"	i
kpts	utils/general.py	/^                kpts = x[:, 6:]$/;"	v	class:non_max_suppression_kpt.only
labels	export.py	/^    labels = model.names$/;"	v
labels	train.py	/^            labels = np.concatenate(dataset.labels, 0)$/;"	v	class:train.names
labels	train_aux.py	/^            labels = np.concatenate(dataset.labels, 0)$/;"	v	class:train.names
labels_to_class_weights	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
labels_to_class_weights	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
labels_to_class_weights	utils/general.py	/^def labels_to_class_weights(labels, nc=80):$/;"	f
labels_to_image_weights	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
labels_to_image_weights	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
labels_to_image_weights	utils/general.py	/^def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):$/;"	f
legend	utils/metrics.py	/^    if 0 < len(names) < 21:  # display per-class legend if < 21 classes$/;"	c	function:plot_mc_curve
legend	utils/metrics.py	/^    if 0 < len(names) < 21:  # display per-class legend if < 21 classes$/;"	c	function:plot_pr_curve
letterbox	models/common.py	/^from utils.datasets import letterbox$/;"	i
letterbox	utils/datasets.py	/^def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):$/;"	f
lf	train.py	/^        lf = lambda x: (1 - x \/ (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear$/;"	v	class:train.names
lf	train.py	/^        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']$/;"	v	class:train.names
lf	train_aux.py	/^        lf = lambda x: (1 - x \/ (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear$/;"	v	class:train.names
lf	train_aux.py	/^        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']$/;"	v	class:train.names
load_classifier	detect.py	/^from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel$/;"	i
load_classifier	utils/torch_utils.py	/^def load_classifier(name='resnet101', n=2):$/;"	f
load_image	utils/datasets.py	/^def load_image(self, index):$/;"	f
load_mosaic	utils/datasets.py	/^def load_mosaic(self, index):$/;"	f
load_mosaic9	utils/datasets.py	/^def load_mosaic9(self, index):$/;"	f
load_samples	utils/datasets.py	/^def load_samples(self, index):$/;"	f
load_segmentations	utils/datasets.py	/^def load_segmentations(self, index):$/;"	f
log	utils/wandb_logging/wandb_utils.py	/^    def log(self, log_dict):$/;"	m	class:WandbLogger
log_dataset_artifact	utils/wandb_logging/wandb_utils.py	/^    def log_dataset_artifact(self, data_file, single_cls, project, overwrite_config=False):$/;"	m	class:WandbLogger
log_model	utils/wandb_logging/wandb_utils.py	/^    def log_model(self, path, opt, epoch, fitness_score, best_model=False):$/;"	m	class:WandbLogger
log_training_progress	utils/wandb_logging/wandb_utils.py	/^    def log_training_progress(self, predn, path, names):$/;"	m	class:WandbLogger
logger	models/yolo.py	/^logger = logging.getLogger(__name__)$/;"	v
logger	train.py	/^logger = logging.getLogger(__name__)$/;"	v
logger	train_aux.py	/^logger = logging.getLogger(__name__)$/;"	v
logger	utils/datasets.py	/^logger = logging.getLogger(__name__)$/;"	v
logger	utils/torch_utils.py	/^logger = logging.getLogger(__name__)$/;"	v
logging	models/yolo.py	/^import logging$/;"	i
logging	train.py	/^import logging$/;"	i
logging	train_aux.py	/^import logging$/;"	i
logging	utils/add_nms.py	/^import logging$/;"	i
logging	utils/datasets.py	/^import logging$/;"	i
logging	utils/general.py	/^import logging$/;"	i
logging	utils/torch_utils.py	/^import logging$/;"	i
lr	train.py	/^        lr = [x['lr'] for x in optimizer.param_groups]  # for tensorboard$/;"	v	class:train.names
lr	train_aux.py	/^        lr = [x['lr'] for x in optimizer.param_groups]  # for tensorboard$/;"	v	class:train.names
lr_scheduler	train.py	/^import torch.optim.lr_scheduler as lr_scheduler$/;"	i
lr_scheduler	train_aux.py	/^import torch.optim.lr_scheduler as lr_scheduler$/;"	i
mAP	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
mAP	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
make_divisible	models/common.py	/^from utils.general import non_max_suppression, make_divisible, scale_coords, increment_path, xyxy2xywh$/;"	i
make_divisible	models/yolo.py	/^from utils.general import make_divisible, check_file, set_logging$/;"	i
make_divisible	utils/general.py	/^def make_divisible(x, divisor):$/;"	f
map_val_table_path	utils/wandb_logging/wandb_utils.py	/^    def map_val_table_path(self):$/;"	m	class:WandbLogger
math	models/common.py	/^import math$/;"	i
math	train.py	/^import math$/;"	i
math	train_aux.py	/^import math$/;"	i
math	utils/datasets.py	/^import math$/;"	i
math	utils/general.py	/^import math$/;"	i
math	utils/plots.py	/^import math$/;"	i
math	utils/torch_utils.py	/^import math$/;"	i
matplotlib	utils/metrics.py	/^import matplotlib.pyplot as plt$/;"	i
matplotlib	utils/plots.py	/^import matplotlib$/;"	i
matplotlib	utils/plots.py	/^import matplotlib.pyplot as plt$/;"	i
matrix	utils/metrics.py	/^    def matrix(self):$/;"	m	class:ConfusionMatrix
mem	train.py	/^                mem = '%.3gG' % (torch.cuda.memory_reserved() \/ 1E9 if torch.cuda.is_available() else 0)  # (GB)$/;"	v	class:train.names
mem	train_aux.py	/^                mem = '%.3gG' % (torch.cuda.memory_reserved() \/ 1E9 if torch.cuda.is_available() else 0)  # (GB)$/;"	v	class:train.names
meta	train.py	/^        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)$/;"	v	class:train.names
meta	train_aux.py	/^        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)$/;"	v	class:train.names
metadata	deploy/triton-inference-server/client.py	/^            metadata = triton_client.get_model_metadata(FLAGS.model)$/;"	v
metric	utils/autoanchor.py	/^    def metric(k):  # compute metric$/;"	f	function:check_anchors
metric	utils/autoanchor.py	/^    def metric(k, wh):  # compute metrics$/;"	f	function:kmean_anchors
mloss	train.py	/^                mloss = (mloss * i + loss_items) \/ (i + 1)  # update mean losses$/;"	v	class:train.names
mloss	train.py	/^        mloss = torch.zeros(4, device=device)  # mean losses$/;"	v	class:train.names
mloss	train_aux.py	/^                mloss = (mloss * i + loss_items) \/ (i + 1)  # update mean losses$/;"	v	class:train.names
mloss	train_aux.py	/^        mloss = torch.zeros(4, device=device)  # mean losses$/;"	v	class:train.names
mo	export.py	/^            mo = RegisterNMS(f)$/;"	v
model	export.py	/^                model = End2End(model,opt.topk_all,opt.iou_thres,opt.conf_thres,opt.max_wh,device,len(labels))$/;"	v
model	export.py	/^    model = attempt_load(opt.weights, map_location=device)  # load FP32 model$/;"	v
model	models/yolo.py	/^    model = Model(opt.cfg).to(device)$/;"	v
model	train.py	/^                                                 model=ema.ema,$/;"	v	class:train.names
model	train.py	/^                                          model=attempt_load(m, device).half(),$/;"	v	class:train.names
model	train.py	/^        model = DDP(model, device_ids=[opt.local_rank], output_device=opt.local_rank,$/;"	v	class:train.names
model	train.py	/^        model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create$/;"	v	class:train.names
model	train.py	/^        model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create$/;"	v	class:train.names
model	train.py	/^        model = torch.nn.DataParallel(model)$/;"	v	class:train.names
model	train.py	/^        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)$/;"	v	class:train.names
model	train_aux.py	/^                                                 model=ema.ema,$/;"	v	class:train.names
model	train_aux.py	/^                                          model=attempt_load(m, device).half(),$/;"	v	class:train.names
model	train_aux.py	/^        model = DDP(model, device_ids=[opt.local_rank], output_device=opt.local_rank,$/;"	v	class:train.names
model	train_aux.py	/^        model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create$/;"	v	class:train.names
model	train_aux.py	/^        model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create$/;"	v	class:train.names
model	train_aux.py	/^        model = torch.nn.DataParallel(model)$/;"	v	class:train.names
model	train_aux.py	/^        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)$/;"	v	class:train.names
model_info	models/yolo.py	/^    select_device, copy_attr$/;"	i
model_info	utils/torch_utils.py	/^def model_info(model, verbose=False, img_size=640):$/;"	f
models	export.py	/^import models$/;"	i
n	train.py	/^                n = min(5, len(x))  # number of previous results to consider$/;"	v	class:train.names
n	train_aux.py	/^                n = min(5, len(x))  # number of previous results to consider$/;"	v	class:train.names
name	train.py	/^                                            name='run_' + wandb_logger.wandb_run.id + '_model',$/;"	v	class:train.names
name	train_aux.py	/^                                            name='run_' + wandb_logger.wandb_run.id + '_model',$/;"	v	class:train.names
names	hubconf.py	/^                model.names = ckpt['model'].names  # set class names attribute$/;"	c	function:create
names	hubconf.py	/^    hub_model.names = model.names  # class names$/;"	c	function:custom
names	models/common.py	/^        self.names = names  # class names$/;"	c	function:Detections.__init__
names	train.py	/^    names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names$/;"	c	function:train
names	train_aux.py	/^    names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names$/;"	c	function:train
nargs	deploy/triton-inference-server/client.py	/^                        nargs='?',$/;"	v
nd	utils/aws/resume.py	/^    nd = len(d)  # number of devices$/;"	v
new_video	utils/datasets.py	/^    def new_video(self, path):$/;"	m	class:LoadImages
ng	train.py	/^                ng = len(meta)$/;"	v	class:train.names
ng	train_aux.py	/^                ng = len(meta)$/;"	v	class:train.names
ni	train.py	/^            ni = i + nb * epoch  # number integrated batches (since train start)$/;"	v	class:train.names
ni	train_aux.py	/^            ni = i + nb * epoch  # number integrated batches (since train start)$/;"	v	class:train.names
nms	models/yolo.py	/^    def nms(self, mode=True):  # add or remove NMS module$/;"	m	class:Model
nn	export.py	/^import torch.nn as nn$/;"	i
nn	models/common.py	/^import torch.nn as nn$/;"	i
nn	models/common.py	/^import torch.nn.functional as F$/;"	i
nn	models/experimental.py	/^import torch.nn as nn$/;"	i
nn	train.py	/^import torch.nn as nn$/;"	i
nn	train.py	/^import torch.nn.functional as F$/;"	i
nn	train_aux.py	/^import torch.nn as nn$/;"	i
nn	train_aux.py	/^import torch.nn.functional as F$/;"	i
nn	utils/activations.py	/^import torch.nn as nn$/;"	i
nn	utils/activations.py	/^import torch.nn.functional as F$/;"	i
nn	utils/datasets.py	/^import torch.nn.functional as F$/;"	i
nn	utils/loss.py	/^import torch.nn as nn$/;"	i
nn	utils/loss.py	/^import torch.nn.functional as F$/;"	i
nn	utils/torch_utils.py	/^    import torch.nn.utils.prune as prune$/;"	i
nn	utils/torch_utils.py	/^import torch.nn as nn$/;"	i
nn	utils/torch_utils.py	/^import torch.nn.functional as F$/;"	i
non_max_suppression	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
non_max_suppression	models/common.py	/^from utils.general import non_max_suppression, make_divisible, scale_coords, increment_path, xyxy2xywh$/;"	i
non_max_suppression	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
non_max_suppression	utils/general.py	/^def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,$/;"	f
non_max_suppression_kpt	utils/general.py	/^def non_max_suppression_kpt(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,$/;"	f
np	deploy/triton-inference-server/client.py	/^import numpy as np$/;"	i
np	deploy/triton-inference-server/processing.py	/^import numpy as np$/;"	i
np	deploy/triton-inference-server/render.py	/^import numpy as np$/;"	i
np	hubconf.py	/^    import numpy as np$/;"	i
np	models/common.py	/^import numpy as np$/;"	i
np	models/experimental.py	/^import numpy as np$/;"	i
np	test.py	/^import numpy as np$/;"	i
np	train.py	/^import numpy as np$/;"	i
np	train_aux.py	/^import numpy as np$/;"	i
np	utils/add_nms.py	/^import numpy as np$/;"	i
np	utils/autoanchor.py	/^import numpy as np$/;"	i
np	utils/datasets.py	/^import numpy as np$/;"	i
np	utils/general.py	/^import numpy as np$/;"	i
np	utils/metrics.py	/^import numpy as np$/;"	i
np	utils/plots.py	/^import numpy as np$/;"	i
npr	train.py	/^                npr = np.random$/;"	v	class:train.names
npr	train_aux.py	/^                npr = np.random$/;"	v	class:train.names
ns	train.py	/^                    ns = [math.ceil(x * sf \/ gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)$/;"	v	class:train.names
ns	train_aux.py	/^                    ns = [math.ceil(x * sf \/ gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)$/;"	v	class:train.names
num_dets	deploy/triton-inference-server/client.py	/^            num_dets = results.as_numpy("num_dets")$/;"	v
num_dets	deploy/triton-inference-server/client.py	/^        num_dets = results.as_numpy(OUTPUT_NAMES[0])$/;"	v
one_cycle	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
one_cycle	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
one_cycle	utils/general.py	/^def one_cycle(y1=0.0, y2=1.0, steps=100):$/;"	f
only	utils/general.py	/^        else:  # best class only$/;"	c	function:non_max_suppression
only	utils/general.py	/^        else:  # best class only$/;"	c	function:non_max_suppression_kpt
onnx	export.py	/^        import onnx$/;"	i
onnx	utils/add_nms.py	/^import onnx$/;"	i
onnx_model	export.py	/^        onnx_model = onnx.load(f)  # load onnx model$/;"	v
onnxsim	export.py	/^                import onnxsim$/;"	i
opt	detect.py	/^    opt = parser.parse_args()$/;"	v
opt	export.py	/^    opt = parser.parse_args()$/;"	v
opt	models/yolo.py	/^    opt = parser.parse_args()$/;"	v
opt	test.py	/^    opt = parser.parse_args()$/;"	v
opt	train.py	/^            opt = argparse.Namespace(**yaml.load(f, Loader=yaml.SafeLoader))  # replace$/;"	v	class:train.names
opt	train_aux.py	/^            opt = argparse.Namespace(**yaml.load(f, Loader=yaml.SafeLoader))  # replace$/;"	v	class:train.names
opt	utils/aws/resume.py	/^        opt = yaml.load(f, Loader=yaml.SafeLoader)$/;"	v
opt	utils/wandb_logging/log_dataset.py	/^    opt = parser.parse_args()$/;"	v
optim	train.py	/^import torch.optim as optim$/;"	i
optim	train.py	/^import torch.optim.lr_scheduler as lr_scheduler$/;"	i
optim	train_aux.py	/^import torch.optim as optim$/;"	i
optim	train_aux.py	/^import torch.optim.lr_scheduler as lr_scheduler$/;"	i
optimize_for_mobile	export.py	/^from torch.utils.mobile_optimizer import optimize_for_mobile$/;"	i
optimizer	train.py	/^        optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum$/;"	v	class:train.names
optimizer	train.py	/^        optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)$/;"	v	class:train.names
optimizer	train_aux.py	/^        optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum$/;"	v	class:train.names
optimizer	train_aux.py	/^        optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)$/;"	v	class:train.names
os	test.py	/^import os$/;"	i
os	train.py	/^import os$/;"	i
os	train_aux.py	/^import os$/;"	i
os	utils/aws/resume.py	/^import os$/;"	i
os	utils/datasets.py	/^import os$/;"	i
os	utils/general.py	/^import os$/;"	i
os	utils/google_utils.py	/^import os$/;"	i
os	utils/plots.py	/^import os$/;"	i
os	utils/torch_utils.py	/^import os$/;"	i
out	deploy/triton-inference-server/client.py	/^                out = cv2.VideoWriter(FLAGS.out, fourcc, FLAGS.fps, (frame.shape[1], frame.shape[0]))$/;"	v
out	deploy/triton-inference-server/client.py	/^        out = None$/;"	v
output_axes	export.py	/^                output_axes = {$/;"	v
output_names	export.py	/^                          output_names=output_names,$/;"	v
output_names	export.py	/^                    output_names = ['num_dets', 'det_boxes', 'det_scores', 'det_classes']$/;"	v
output_names	export.py	/^                    output_names = ['output']$/;"	v
output_names	export.py	/^        output_names = ['classes', 'boxes'] if y is None else ['output']$/;"	v
output_to_keypoint	utils/plots.py	/^def output_to_keypoint(output):$/;"	f
output_to_target	test.py	/^from utils.plots import plot_images, output_to_target, plot_study_txt$/;"	i
output_to_target	utils/plots.py	/^def output_to_target(output):$/;"	f
outputs	deploy/triton-inference-server/client.py	/^                                          outputs=outputs,$/;"	v
outputs	deploy/triton-inference-server/client.py	/^                                      outputs=outputs,$/;"	v
outputs	deploy/triton-inference-server/client.py	/^        outputs = []$/;"	v
pafy	utils/datasets.py	/^                import pafy$/;"	i
pandas	models/common.py	/^    def pandas(self):$/;"	m	class:Detections
parent	train.py	/^                parent = 'single'  # parent selection method: 'single' or 'weighted'$/;"	v	class:train.names
parent	train_aux.py	/^                parent = 'single'  # parent selection method: 'single' or 'weighted'$/;"	v	class:train.names
parse_model	models/yolo.py	/^def parse_model(d, ch):  # model_dict, input_channels(3)$/;"	f
parser	deploy/triton-inference-server/client.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	detect.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	export.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	models/yolo.py	/^    parser = argparse.ArgumentParser()$/;"	v
parser	test.py	/^    parser = argparse.ArgumentParser(prog='test.py')$/;"	v
parser	utils/wandb_logging/log_dataset.py	/^    parser = argparse.ArgumentParser()$/;"	v
pastein	utils/datasets.py	/^def pastein(image, labels, sample_labels, sample_images, sample_masks):$/;"	f
path	utils/aws/resume.py	/^path = Path('').resolve()$/;"	v
pbar	train.py	/^            pbar = tqdm(pbar, total=nb)  # progress bar$/;"	v	class:train.names
pbar	train.py	/^        pbar = enumerate(dataloader)$/;"	v	class:train.names
pbar	train_aux.py	/^            pbar = tqdm(pbar, total=nb)  # progress bar$/;"	v	class:train.names
pbar	train_aux.py	/^        pbar = enumerate(dataloader)$/;"	v	class:train.names
pd	models/common.py	/^import pandas as pd$/;"	i
pd	utils/general.py	/^import pandas as pd$/;"	i
pd	utils/plots.py	/^import pandas as pd$/;"	i
pickle	utils/datasets.py	/^import pickle$/;"	i
pkg	utils/general.py	/^    import pkg_resources as pkg$/;"	i
platform	utils/general.py	/^import platform$/;"	i
platform	utils/google_utils.py	/^import platform$/;"	i
platform	utils/torch_utils.py	/^import platform$/;"	i
plot	utils/metrics.py	/^    def plot(self, save_dir='', names=()):$/;"	m	class:ConfusionMatrix
plot_evolution	train.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_evolution	train_aux.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_evolution	utils/plots.py	/^def plot_evolution(yaml_file='data\/hyp.finetune.yaml'):  # from utils.plots import *; plot_evolution()$/;"	f
plot_images	test.py	/^from utils.plots import plot_images, output_to_target, plot_study_txt$/;"	i
plot_images	train.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_images	train_aux.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_images	utils/plots.py	/^def plot_images(images, targets, paths=None, fname='images.jpg', names=None, max_size=640, max_subplots=16):$/;"	f
plot_labels	train.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_labels	train_aux.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_labels	utils/plots.py	/^def plot_labels(labels, names=(), save_dir=Path(''), loggers=None):$/;"	f
plot_lr_scheduler	utils/plots.py	/^def plot_lr_scheduler(optimizer, scheduler, epochs=300, save_dir=''):$/;"	f
plot_mc_curve	utils/metrics.py	/^def plot_mc_curve(px, py, save_dir='mc_curve.png', names=(), xlabel='Confidence', ylabel='Metric'):$/;"	f
plot_one_box	detect.py	/^from utils.plots import plot_one_box$/;"	i
plot_one_box	models/common.py	/^from utils.plots import color_list, plot_one_box$/;"	i
plot_one_box	utils/plots.py	/^def plot_one_box(x, img, color=None, label=None, line_thickness=3):$/;"	f
plot_one_box_PIL	utils/plots.py	/^def plot_one_box_PIL(box, img, color=None, label=None, line_thickness=None):$/;"	f
plot_pr_curve	utils/metrics.py	/^def plot_pr_curve(px, py, ap, save_dir='pr_curve.png', names=()):$/;"	f
plot_results	train.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_results	train_aux.py	/^from utils.plots import plot_images, plot_labels, plot_results, plot_evolution$/;"	i
plot_results	utils/plots.py	/^def plot_results(start=0, stop=0, bucket='', id=(), labels=(), save_dir=''):$/;"	f
plot_results_overlay	utils/plots.py	/^def plot_results_overlay(start=0, stop=0):  # from utils.plots import *; plot_results_overlay()$/;"	f
plot_skeleton_kpts	utils/plots.py	/^def plot_skeleton_kpts(im, kpts, steps, orig_shape=None):$/;"	f
plot_study_txt	test.py	/^from utils.plots import plot_images, output_to_target, plot_study_txt$/;"	i
plot_study_txt	utils/plots.py	/^def plot_study_txt(path='', x=None):  # from utils.plots import *; plot_study_txt()$/;"	f
plot_targets_txt	utils/plots.py	/^def plot_targets_txt():  # from utils.plots import *; plot_targets_txt()$/;"	f
plot_test_txt	utils/plots.py	/^def plot_test_txt():  # from utils.plots import *; plot_test()$/;"	f
plot_wh_methods	utils/plots.py	/^def plot_wh_methods():  # from utils.plots import *; plot_wh_methods()$/;"	f
plots	train.py	/^                                                 plots=plots and final_epoch,$/;"	v	class:train.names
plots	train.py	/^                                          plots=False,$/;"	v	class:train.names
plots	train_aux.py	/^                                                 plots=plots and final_epoch,$/;"	v	class:train.names
plots	train_aux.py	/^                                          plots=False,$/;"	v	class:train.names
plt	utils/metrics.py	/^import matplotlib.pyplot as plt$/;"	i
plt	utils/plots.py	/^import matplotlib.pyplot as plt$/;"	i
port	utils/aws/resume.py	/^port = 0  # --master_port$/;"	v
postprocess	deploy/triton-inference-server/client.py	/^from processing import preprocess, postprocess$/;"	i
postprocess	deploy/triton-inference-server/processing.py	/^def postprocess(num_dets, det_boxes, det_scores, det_classes, img_w, img_h, input_shape, letter_box=True):$/;"	f
pred	train.py	/^                pred = model(imgs)  # forward$/;"	v	class:train.names
pred	train_aux.py	/^                pred = model(imgs)  # forward$/;"	v	class:train.names
prefix	train.py	/^            prefix = colorstr('tensorboard: ')$/;"	v	class:train.names
prefix	train_aux.py	/^            prefix = colorstr('tensorboard: ')$/;"	v	class:train.names
preprocess	deploy/triton-inference-server/client.py	/^from processing import preprocess, postprocess$/;"	i
preprocess	deploy/triton-inference-server/processing.py	/^def preprocess(img, input_shape, letter_box=True):$/;"	f
print	models/common.py	/^    def print(self):$/;"	m	class:Detections
print	utils/metrics.py	/^    def print(self):$/;"	m	class:ConfusionMatrix
print_mutation	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
print_mutation	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
print_mutation	utils/general.py	/^def print_mutation(hyp, results, yaml_file='hyp_evolved.yaml', bucket=''):$/;"	f
print_results	utils/autoanchor.py	/^    def print_results(k):$/;"	f	function:kmean_anchors
private_key	deploy/triton-inference-server/client.py	/^            private_key=FLAGS.private_key,$/;"	v
process_batch	utils/metrics.py	/^    def process_batch(self, detections, labels):$/;"	m	class:ConfusionMatrix
process_wandb_config_ddp_mode	utils/wandb_logging/wandb_utils.py	/^def process_wandb_config_ddp_mode(opt):$/;"	f
profile	utils/torch_utils.py	/^        from thop import profile$/;"	i
profile	utils/torch_utils.py	/^def profile(x, ops, n=100, device=None):$/;"	f
profile_idetection	utils/plots.py	/^def profile_idetection(start=0, stop=0, labels=(), save_dir=''):$/;"	f
prune	utils/torch_utils.py	/^    import torch.nn.utils.prune as prune$/;"	i
prune	utils/torch_utils.py	/^def prune(model, amount=0.3):$/;"	f
ps_roi_align	utils/datasets.py	/^from torchvision.ops import roi_pool, roi_align, ps_roi_pool, ps_roi_align$/;"	i
ps_roi_pool	utils/datasets.py	/^from torchvision.ops import roi_pool, roi_align, ps_roi_pool, ps_roi_align$/;"	i
py	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
py	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
random	detect.py	/^from numpy import random$/;"	i
random	models/experimental.py	/^import random$/;"	i
random	train.py	/^import random$/;"	i
random	train_aux.py	/^import random$/;"	i
random	utils/datasets.py	/^import random$/;"	i
random	utils/general.py	/^import random$/;"	i
random	utils/plots.py	/^import random$/;"	i
random_perspective	utils/datasets.py	/^def random_perspective(img, targets=(), segments=(), degrees=10, translate=.1, scale=.1, shear=10, perspective=0.0,$/;"	f
re	utils/general.py	/^import re$/;"	i
register_nms	utils/add_nms.py	/^    def register_nms($/;"	m	class:RegisterNMS
remove_background	utils/datasets.py	/^def remove_background(img, labels, segments):$/;"	f
remove_prefix	utils/wandb_logging/wandb_utils.py	/^def remove_prefix(from_string, prefix=WANDB_ARTIFACT_PREFIX):$/;"	f
render	models/common.py	/^    def render(self):$/;"	m	class:Detections
render_box	deploy/triton-inference-server/client.py	/^from render import render_box, render_filled_box, get_text_size, render_text, RAND_COLORS$/;"	i
render_box	deploy/triton-inference-server/render.py	/^def render_box(img, box, color=(200, 200, 200)):$/;"	f
render_filled_box	deploy/triton-inference-server/client.py	/^from render import render_box, render_filled_box, get_text_size, render_text, RAND_COLORS$/;"	i
render_filled_box	deploy/triton-inference-server/render.py	/^def render_filled_box(img, box, color=(200, 200, 200)):$/;"	f
render_text	deploy/triton-inference-server/client.py	/^from render import render_box, render_filled_box, get_text_size, render_text, RAND_COLORS$/;"	i
render_text	deploy/triton-inference-server/render.py	/^def render_text(img, text, pos, color=(200, 200, 200), normalised_scaling=1.0):$/;"	f
repeat	utils/datasets.py	/^from itertools import repeat$/;"	i
replicate	utils/datasets.py	/^def replicate(img, labels):$/;"	f
repvgg_convert	models/common.py	/^    def repvgg_convert(self):$/;"	m	class:RepConv
requests	models/common.py	/^import requests$/;"	i
requests	utils/google_utils.py	/^import requests$/;"	i
required	deploy/triton-inference-server/client.py	/^                        required=False,$/;"	v
resample_segments	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
resample_segments	utils/general.py	/^def resample_segments(segments, n=1000):$/;"	f
result	deploy/triton-inference-server/client.py	/^            result = results.as_numpy(output)$/;"	v
results	deploy/triton-inference-server/client.py	/^            results = triton_client.infer(model_name=FLAGS.model,$/;"	v
results	deploy/triton-inference-server/client.py	/^        results = triton_client.infer(model_name=FLAGS.model,$/;"	v
results	train.py	/^            results = train(hyp.copy(), opt, device)$/;"	v	class:train.names
results	train_aux.py	/^            results = train(hyp.copy(), opt, device)$/;"	v	class:train.names
revert_sync_batchnorm	utils/torch_utils.py	/^def revert_sync_batchnorm(module):$/;"	f
roi_align	utils/datasets.py	/^from torchvision.ops import roi_pool, roi_align, ps_roi_pool, ps_roi_align$/;"	i
roi_pool	utils/datasets.py	/^from torchvision.ops import roi_pool, roi_align, ps_roi_pool, ps_roi_align$/;"	i
root_certificates	deploy/triton-inference-server/client.py	/^            root_certificates=FLAGS.root_certificates,$/;"	v
s	train.py	/^                s = ('%10s' * 2 + '%10.4g' * 6) % ($/;"	v	class:train.names
s	train_aux.py	/^                s = ('%10s' * 2 + '%10.4g' * 6) % ($/;"	v	class:train.names
sample_segments	utils/datasets.py	/^def sample_segments(img, labels, segments, probability=0.5):$/;"	f
save	models/common.py	/^    def save(self, save_dir='runs\/hub\/exp'):$/;"	m	class:Detections
save	utils/add_nms.py	/^    def save(self, output_path):$/;"	m	class:RegisterNMS
save_conf	test.py	/^             save_conf=opt.save_conf,$/;"	v
save_dir	train.py	/^                                                 save_dir=save_dir,$/;"	v	class:train.names
save_dir	train.py	/^                                          save_dir=save_dir,$/;"	v	class:train.names
save_dir	train_aux.py	/^                                                 save_dir=save_dir,$/;"	v	class:train.names
save_dir	train_aux.py	/^                                          save_dir=save_dir,$/;"	v	class:train.names
save_hybrid	test.py	/^             save_hybrid=opt.save_hybrid,$/;"	v
save_image	utils/datasets.py	/^from torchvision.utils import save_image$/;"	i
save_json	train.py	/^                                          save_json=True,$/;"	v	class:train.names
save_json	train_aux.py	/^                                          save_json=True,$/;"	v	class:train.names
save_txt	test.py	/^             save_txt=opt.save_txt | opt.save_hybrid,$/;"	v
scale_coords	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
scale_coords	models/common.py	/^from utils.general import non_max_suppression, make_divisible, scale_coords, increment_path, xyxy2xywh$/;"	i
scale_coords	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
scale_coords	utils/general.py	/^def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):$/;"	f
scale_img	models/yolo.py	/^    select_device, copy_attr$/;"	i
scale_img	utils/torch_utils.py	/^def scale_img(img, ratio=1.0, same_shape=False, gs=32):  # img(16,3,256,416)$/;"	f
segment2box	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
segment2box	utils/general.py	/^def segment2box(segment, width=640, height=640):$/;"	f
segments2boxes	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
segments2boxes	utils/general.py	/^def segments2boxes(segments):$/;"	f
select_device	detect.py	/^from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel$/;"	i
select_device	export.py	/^from utils.torch_utils import select_device$/;"	i
select_device	hubconf.py	/^from utils.torch_utils import select_device$/;"	i
select_device	models/yolo.py	/^    select_device, copy_attr$/;"	i
select_device	test.py	/^from utils.torch_utils import select_device, time_synchronized, TracedModel$/;"	i
select_device	train.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
select_device	train_aux.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
select_device	utils/torch_utils.py	/^def select_device(device='', batch_size=None):$/;"	f
set_logging	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
set_logging	export.py	/^from utils.general import set_logging, check_img_size$/;"	i
set_logging	hubconf.py	/^from utils.general import check_requirements, set_logging$/;"	i
set_logging	models/yolo.py	/^from utils.general import make_divisible, check_file, set_logging$/;"	i
set_logging	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
set_logging	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
set_logging	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
set_logging	utils/general.py	/^def set_logging(rank=-1):$/;"	f
setup_training	utils/wandb_logging/wandb_utils.py	/^    def setup_training(self, opt, data_dict):$/;"	m	class:WandbLogger
sf	train.py	/^                sf = sz \/ max(imgs.shape[2:])  # scale factor$/;"	v	class:train.names
sf	train_aux.py	/^                sf = sz \/ max(imgs.shape[2:])  # scale factor$/;"	v	class:train.names
shape_inference	utils/add_nms.py	/^from onnx import shape_inference$/;"	i
shapes	export.py	/^                    shapes = [opt.batch_size, 1, opt.batch_size, opt.topk_all, 4,$/;"	v
show	models/common.py	/^    def show(self):$/;"	m	class:Detections
shutil	utils/datasets.py	/^import shutil$/;"	i
single_cls	train.py	/^                                                 single_cls=opt.single_cls,$/;"	v	class:train.names
single_cls	train.py	/^                                          single_cls=opt.single_cls,$/;"	v	class:train.names
single_cls	train_aux.py	/^                                                 single_cls=opt.single_cls,$/;"	v	class:train.names
single_cls	train_aux.py	/^                                          single_cls=opt.single_cls,$/;"	v	class:train.names
size	deploy/triton-inference-server/client.py	/^                size = get_text_size(frame, f"{COCOLabels(box.classID).name}: {box.confidence:.2f}", normalised_scaling=0.6)$/;"	v
size	deploy/triton-inference-server/client.py	/^            size = get_text_size(input_image, f"{COCOLabels(box.classID).name}: {box.confidence:.2f}", normalised_scaling=0.6)$/;"	v
size_absolute	deploy/triton-inference-server/boundingbox.py	/^    def size_absolute(self):$/;"	m	class:BoundingBox
size_normalized	deploy/triton-inference-server/boundingbox.py	/^    def size_normalized(self):$/;"	m	class:BoundingBox
smooth_BCE	utils/loss.py	/^def smooth_BCE(eps=0.1):  # https:\/\/github.com\/ultralytics\/yolov3\/issues\/238#issuecomment-598028441$/;"	f
sn	utils/metrics.py	/^            import seaborn as sn$/;"	i
sns	utils/plots.py	/^import seaborn as sns$/;"	i
socket	utils/general.py	/^    import socket$/;"	i
sparsity	utils/torch_utils.py	/^def sparsity(model):$/;"	f
sqrt	deploy/triton-inference-server/render.py	/^from math import sqrt$/;"	i
ssl	deploy/triton-inference-server/client.py	/^            ssl=FLAGS.ssl,$/;"	v
start_epoch	train.py	/^        start_epoch = ckpt['epoch'] + 1$/;"	v	class:train.names
start_epoch	train_aux.py	/^        start_epoch = ckpt['epoch'] + 1$/;"	v	class:train.names
state_dict	train.py	/^        state_dict = ckpt['model'].float().state_dict()  # to FP32$/;"	v	class:train.names
state_dict	train.py	/^        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect$/;"	v	class:train.names
state_dict	train_aux.py	/^        state_dict = ckpt['model'].float().state_dict()  # to FP32$/;"	v	class:train.names
state_dict	train_aux.py	/^        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect$/;"	v	class:train.names
statistics	deploy/triton-inference-server/client.py	/^            statistics = triton_client.get_inference_statistics(model_name=FLAGS.model)$/;"	v
stride	models/yolo.py	/^    stride = None  # strides computed during build$/;"	v	class:Detect
stride	models/yolo.py	/^    stride = None  # strides computed during build$/;"	v	class:IAuxDetect
stride	models/yolo.py	/^    stride = None  # strides computed during build$/;"	v	class:IBin
stride	models/yolo.py	/^    stride = None  # strides computed during build$/;"	v	class:IDetect
stride	models/yolo.py	/^    stride = None  # strides computed during build$/;"	v	class:IKeypoint
stride	utils/loss.py	/^    stride = None  # strides computed during build$/;"	v	class:SigmoidBin
strip_optimizer	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
strip_optimizer	train.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
strip_optimizer	train_aux.py	/^    check_requirements, print_mutation, set_logging, one_cycle, colorstr$/;"	i
strip_optimizer	utils/general.py	/^def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()$/;"	f
subprocess	utils/general.py	/^import subprocess$/;"	i
subprocess	utils/google_utils.py	/^import subprocess$/;"	i
subprocess	utils/torch_utils.py	/^import subprocess$/;"	i
switch_to_deploy	models/common.py	/^    def switch_to_deploy(self):$/;"	m	class:ConvBN
switch_to_deploy	models/common.py	/^    def switch_to_deploy(self):$/;"	m	class:RepConv_OREPA
symbolic	models/experimental.py	/^    def symbolic(g, boxes, scores, max_output_boxes_per_class, iou_threshold, score_threshold):$/;"	m	class:ORT_NMS
symbolic	models/experimental.py	/^    def symbolic(g,$/;"	m	class:TRT_NMS
sys	deploy/triton-inference-server/client.py	/^import sys$/;"	i
sys	export.py	/^import sys$/;"	i
sys	models/yolo.py	/^import sys$/;"	i
sys	utils/aws/resume.py	/^import sys$/;"	i
sys	utils/wandb_logging/wandb_utils.py	/^import sys$/;"	i
sz	train.py	/^                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) \/\/ gs * gs  # size$/;"	v	class:train.names
sz	train_aux.py	/^                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) \/\/ gs * gs  # size$/;"	v	class:train.names
t	export.py	/^    t = time.time()$/;"	v
tags	train.py	/^            tags = ['train\/box_loss', 'train\/obj_loss', 'train\/cls_loss',  # train loss$/;"	v	class:train.names
tags	train_aux.py	/^            tags = ['train\/box_loss', 'train\/obj_loss', 'train\/cls_loss',  # train loss$/;"	v	class:train.names
tb_writer	train.py	/^            tb_writer = SummaryWriter(opt.save_dir)  # Tensorboard$/;"	v	class:train.names
tb_writer	train.py	/^        tb_writer = None  # init loggers$/;"	v	class:train.names
tb_writer	train_aux.py	/^            tb_writer = SummaryWriter(opt.save_dir)  # Tensorboard$/;"	v	class:train.names
tb_writer	train_aux.py	/^        tb_writer = None  # init loggers$/;"	v	class:train.names
test	test.py	/^def test(data,$/;"	f
test	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
test	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
testloader	train.py	/^        testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, opt,  # testloader$/;"	v	class:train.names
testloader	train_aux.py	/^        testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, opt,  # testloader$/;"	v	class:train.names
thop	models/yolo.py	/^    import thop  # for FLOPS computation$/;"	i
thop	models/yolo.py	/^    thop = None$/;"	v
thop	utils/torch_utils.py	/^    import thop  # for FLOPS computation$/;"	i
thop	utils/torch_utils.py	/^    thop = None$/;"	v
time	detect.py	/^import time$/;"	i
time	export.py	/^import time$/;"	i
time	train.py	/^import time$/;"	i
time	train_aux.py	/^import time$/;"	i
time	utils/datasets.py	/^import time$/;"	i
time	utils/general.py	/^import time$/;"	i
time	utils/google_utils.py	/^import time$/;"	i
time	utils/torch_utils.py	/^import time$/;"	i
time_synchronized	detect.py	/^from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel$/;"	i
time_synchronized	models/common.py	/^from utils.torch_utils import time_synchronized$/;"	i
time_synchronized	models/yolo.py	/^    select_device, copy_attr$/;"	i
time_synchronized	test.py	/^from utils.torch_utils import select_device, time_synchronized, TracedModel$/;"	i
time_synchronized	utils/torch_utils.py	/^def time_synchronized():$/;"	f
to	train.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
to	train_aux.py	/^import test  # import test.py to get mAP after each epoch$/;"	i
tolist	models/common.py	/^    def tolist(self):$/;"	m	class:Detections
torch	detect.py	/^import torch$/;"	i
torch	detect.py	/^import torch.backends.cudnn as cudnn$/;"	i
torch	export.py	/^import torch$/;"	i
torch	export.py	/^import torch.nn as nn$/;"	i
torch	hubconf.py	/^import torch$/;"	i
torch	models/common.py	/^import torch$/;"	i
torch	models/common.py	/^import torch.nn as nn$/;"	i
torch	models/common.py	/^import torch.nn.functional as F$/;"	i
torch	models/experimental.py	/^import torch$/;"	i
torch	models/experimental.py	/^import torch.nn as nn$/;"	i
torch	models/yolo.py	/^            import yaml  # for torch hub$/;"	i
torch	models/yolo.py	/^import torch$/;"	i
torch	test.py	/^import torch$/;"	i
torch	train.py	/^import torch.distributed as dist$/;"	i
torch	train.py	/^import torch.nn as nn$/;"	i
torch	train.py	/^import torch.nn.functional as F$/;"	i
torch	train.py	/^import torch.optim as optim$/;"	i
torch	train.py	/^import torch.optim.lr_scheduler as lr_scheduler$/;"	i
torch	train.py	/^import torch.utils.data$/;"	i
torch	train_aux.py	/^import torch.distributed as dist$/;"	i
torch	train_aux.py	/^import torch.nn as nn$/;"	i
torch	train_aux.py	/^import torch.nn.functional as F$/;"	i
torch	train_aux.py	/^import torch.optim as optim$/;"	i
torch	train_aux.py	/^import torch.optim.lr_scheduler as lr_scheduler$/;"	i
torch	train_aux.py	/^import torch.utils.data$/;"	i
torch	utils/activations.py	/^import torch$/;"	i
torch	utils/activations.py	/^import torch.nn as nn$/;"	i
torch	utils/activations.py	/^import torch.nn.functional as F$/;"	i
torch	utils/autoanchor.py	/^import torch$/;"	i
torch	utils/aws/resume.py	/^import torch$/;"	i
torch	utils/datasets.py	/^import torch$/;"	i
torch	utils/datasets.py	/^import torch.nn.functional as F$/;"	i
torch	utils/general.py	/^import torch$/;"	i
torch	utils/google_utils.py	/^import torch$/;"	i
torch	utils/loss.py	/^import torch$/;"	i
torch	utils/loss.py	/^import torch.nn as nn$/;"	i
torch	utils/loss.py	/^import torch.nn.functional as F$/;"	i
torch	utils/metrics.py	/^import torch$/;"	i
torch	utils/plots.py	/^import torch$/;"	i
torch	utils/torch_utils.py	/^    import torch.nn.utils.prune as prune$/;"	i
torch	utils/torch_utils.py	/^import torch$/;"	i
torch	utils/torch_utils.py	/^import torch.backends.cudnn as cudnn$/;"	i
torch	utils/torch_utils.py	/^import torch.nn as nn$/;"	i
torch	utils/torch_utils.py	/^import torch.nn.functional as F$/;"	i
torch	utils/wandb_logging/wandb_utils.py	/^import torch$/;"	i
torch_distributed_zero_first	train.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
torch_distributed_zero_first	train_aux.py	/^from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, is_parallel$/;"	i
torch_distributed_zero_first	utils/datasets.py	/^from utils.torch_utils import torch_distributed_zero_first$/;"	i
torch_distributed_zero_first	utils/torch_utils.py	/^def torch_distributed_zero_first(local_rank: int):$/;"	f
torchvision	utils/general.py	/^import torchvision$/;"	i
torchvision	utils/torch_utils.py	/^import torchvision$/;"	i
tqdm	test.py	/^from tqdm import tqdm$/;"	i
tqdm	train.py	/^from tqdm import tqdm$/;"	i
tqdm	train_aux.py	/^from tqdm import tqdm$/;"	i
tqdm	utils/autoanchor.py	/^from tqdm import tqdm$/;"	i
tqdm	utils/datasets.py	/^from tqdm import tqdm$/;"	i
tqdm	utils/wandb_logging/wandb_utils.py	/^from tqdm import tqdm$/;"	i
trace	test.py	/^             trace=not opt.no_trace,$/;"	v
train	train.py	/^def train(hyp, opt, device, tb_writer=None):$/;"	f
train	train_aux.py	/^def train(hyp, opt, device, tb_writer=None):$/;"	f
training_loss	utils/loss.py	/^    def training_loss(self, pred, target):$/;"	m	class:SigmoidBin
transI_fusebn	models/common.py	/^def transI_fusebn(kernel, bn):$/;"	f
triton_client	deploy/triton-inference-server/client.py	/^        triton_client = grpcclient.InferenceServerClient($/;"	v
tritonclient	deploy/triton-inference-server/client.py	/^import tritonclient.grpc as grpcclient$/;"	i
ts	export.py	/^        ts = torch.jit.trace(model, img, strict=False)$/;"	v
tsl	export.py	/^        tsl = optimize_for_mobile(tsl)$/;"	v
tsl	export.py	/^        tsl = torch.jit.trace(model, img, strict=False)$/;"	v
type	deploy/triton-inference-server/client.py	/^                        type=float,$/;"	v
type	deploy/triton-inference-server/client.py	/^                        type=int,$/;"	v
type	deploy/triton-inference-server/client.py	/^                        type=str,$/;"	v
update	utils/datasets.py	/^    def update(self, index, cap):$/;"	m	class:LoadStreams
update	utils/torch_utils.py	/^    def update(self, model):$/;"	m	class:ModelEMA
update_attr	utils/torch_utils.py	/^    def update_attr(self, model, include=(), exclude=('process_group', 'reducer')):$/;"	m	class:ModelEMA
url	deploy/triton-inference-server/client.py	/^            url=FLAGS.url,$/;"	v
utils	train.py	/^import torch.utils.data$/;"	i
utils	train_aux.py	/^import torch.utils.data$/;"	i
utils	utils/torch_utils.py	/^    import torch.nn.utils.prune as prune$/;"	i
v	train.py	/^                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)$/;"	v	class:train.names
v	train.py	/^                v = np.ones(ng)$/;"	v	class:train.names
v	train_aux.py	/^                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)$/;"	v	class:train.names
v	train_aux.py	/^                v = np.ones(ng)$/;"	v	class:train.names
v5_metric	test.py	/^             v5_metric=opt.v5_metric$/;"	v
v5_metric	train.py	/^                                                 v5_metric=opt.v5_metric)$/;"	v	class:train.names
v5_metric	train.py	/^                                          v5_metric=opt.v5_metric)$/;"	v	class:train.names
v5_metric	train_aux.py	/^                                                 v5_metric=opt.v5_metric)$/;"	v	class:train.names
v5_metric	train_aux.py	/^                                          v5_metric=opt.v5_metric)$/;"	v	class:train.names
verbose	deploy/triton-inference-server/client.py	/^            verbose=FLAGS.verbose,$/;"	v
verbose	train.py	/^                                                 verbose=nc < 50 and final_epoch,$/;"	v	class:train.names
verbose	train_aux.py	/^                                                 verbose=nc < 50 and final_epoch,$/;"	v	class:train.names
vid_formats	utils/datasets.py	/^vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes$/;"	v
visu	deploy/triton-inference-server/render.py	/^RAND_COLORS = np.random.randint(50, 255, (64, 3), "int")  # used for class visu$/;"	c
w	train.py	/^                w = fitness(x) - fitness(x).min()  # weights$/;"	v	class:train.names
w	train_aux.py	/^                w = fitness(x) - fitness(x).min()  # weights$/;"	v	class:train.names
wandb	utils/wandb_logging/wandb_utils.py	/^    import wandb$/;"	i
wandb	utils/wandb_logging/wandb_utils.py	/^    wandb = None$/;"	v
wandb_logger	train.py	/^                                                 wandb_logger=wandb_logger,$/;"	v	class:train.names
wandb_logger	train_aux.py	/^                                                 wandb_logger=wandb_logger,$/;"	v	class:train.names
warnings	export.py	/^import warnings$/;"	i
weight_gen	models/common.py	/^    def weight_gen(self):$/;"	m	class:OREPA_3x3_RepConv
weights	utils/general.py	/^            weights = iou * scores[None]  # box weights$/;"	v	class:non_max_suppression.only
weights	utils/general.py	/^            weights = iou * scores[None]  # box weights$/;"	v	class:non_max_suppression_kpt.only
wh_iou	utils/general.py	/^def wh_iou(wh1, wh2):$/;"	f
width	deploy/triton-inference-server/boundingbox.py	/^    def width(self):$/;"	m	class:BoundingBox
window_partition	models/common.py	/^def window_partition(x, window_size):$/;"	f
window_partition_v2	models/common.py	/^def window_partition_v2(x, window_size):$/;"	f
window_reverse	models/common.py	/^def window_reverse(windows, window_size, H, W):$/;"	f
window_reverse_v2	models/common.py	/^def window_reverse_v2(windows, window_size, H, W):$/;"	f
x	test.py	/^        x = list(range(256, 1536 + 128, 128))  # x axis (image sizes)$/;"	v
x	train.py	/^                    x = (x * w.reshape(n, 1)).sum(0) \/ w.sum()  # weighted combination$/;"	v	class:train.names
x	train.py	/^                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection$/;"	v	class:train.names
x	train.py	/^                x = np.loadtxt('evolve.txt', ndmin=2)$/;"	v	class:train.names
x	train.py	/^                x = x[np.argsort(-fitness(x))][:n]  # top n mutations$/;"	v	class:train.names
x	train_aux.py	/^                    x = (x * w.reshape(n, 1)).sum(0) \/ w.sum()  # weighted combination$/;"	v	class:train.names
x	train_aux.py	/^                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection$/;"	v	class:train.names
x	train_aux.py	/^                x = np.loadtxt('evolve.txt', ndmin=2)$/;"	v	class:train.names
x	train_aux.py	/^                x = x[np.argsort(-fitness(x))][:n]  # top n mutations$/;"	v	class:train.names
x	utils/general.py	/^                x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]$/;"	v	class:non_max_suppression_kpt.only
x	utils/general.py	/^                x = torch.cat((box, conf, j.float(), kpts), 1)[conf.view(-1) > conf_thres]$/;"	v	class:non_max_suppression_kpt.only
x	utils/general.py	/^            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]$/;"	v	class:non_max_suppression.only
x	utils/general.py	/^            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]$/;"	v	class:non_max_suppression.only
x	utils/general.py	/^            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]$/;"	v	class:non_max_suppression_kpt.only
x	utils/general.py	/^            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence$/;"	v	class:non_max_suppression.only
x	utils/general.py	/^            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence$/;"	v	class:non_max_suppression_kpt.only
xi	train.py	/^                xi = [0, nw]  # x interp$/;"	v	class:train.names
xi	train_aux.py	/^                xi = [0, nw]  # x interp$/;"	v	class:train.names
xyn2xy	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
xyn2xy	utils/general.py	/^def xyn2xy(x, w=640, h=640, padw=0, padh=0):$/;"	f
xywh2xyxy	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
xywh2xyxy	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
xywh2xyxy	utils/general.py	/^def xywh2xyxy(x):$/;"	f
xywh2xyxy	utils/loss.py	/^from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy$/;"	i
xywh2xyxy	utils/plots.py	/^from utils.general import xywh2xyxy, xyxy2xywh$/;"	i
xywh2xyxy	utils/wandb_logging/wandb_utils.py	/^from utils.general import colorstr, xywh2xyxy, check_dataset$/;"	i
xywhn2xyxy	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
xywhn2xyxy	utils/general.py	/^def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):$/;"	f
xyxy2xywh	detect.py	/^    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path$/;"	i
xyxy2xywh	models/common.py	/^from utils.general import non_max_suppression, make_divisible, scale_coords, increment_path, xyxy2xywh$/;"	i
xyxy2xywh	test.py	/^    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr$/;"	i
xyxy2xywh	utils/datasets.py	/^    resample_segments, clean_str$/;"	i
xyxy2xywh	utils/general.py	/^def xyxy2xywh(x):$/;"	f
xyxy2xywh	utils/plots.py	/^from utils.general import xywh2xyxy, xyxy2xywh$/;"	i
y	export.py	/^        y = None$/;"	v
y	export.py	/^    y = model(img)  # dry run$/;"	v
y	models/yolo.py	/^        y = model(img, profile=True)$/;"	v
y	test.py	/^            y = []  # y axis$/;"	v
yaml	models/yolo.py	/^            import yaml  # for torch hub$/;"	i
yaml	test.py	/^import yaml$/;"	i
yaml	train.py	/^import yaml$/;"	i
yaml	train_aux.py	/^import yaml$/;"	i
yaml	utils/autoanchor.py	/^import yaml$/;"	i
yaml	utils/aws/resume.py	/^import yaml$/;"	i
yaml	utils/general.py	/^import yaml$/;"	i
yaml	utils/plots.py	/^import yaml$/;"	i
yaml	utils/wandb_logging/log_dataset.py	/^import yaml$/;"	i
yaml	utils/wandb_logging/wandb_utils.py	/^import yaml$/;"	i
yaml_file	train.py	/^        yaml_file = Path(opt.save_dir) \/ 'hyp_evolved.yaml'  # save best result here$/;"	v	class:train.names
yaml_file	train_aux.py	/^        yaml_file = Path(opt.save_dir) \/ 'hyp_evolved.yaml'  # save best result here$/;"	v	class:train.names
yolov7	hubconf.py	/^def yolov7(pretrained=True, channels=3, classes=80, autoshape=True):$/;"	f
